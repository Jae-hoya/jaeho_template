import streamlit as st
from uuid import uuid4

from dotenv import load_dotenv

from streamlit_wrapper import create_graph, stream_graph

from langchain_teddynote import logging
from langsmith import Client
from langchain_core.messages import HumanMessage, AIMessage, ChatMessage

load_dotenv()

LANGSMITH_PROJECT = "Agentic RAG System"

logging.langsmith(LANGSMITH_PROJECT)

NAMESPACE = "agentic_rag"

if "langsmith_client" not in st.session_state:
    st.session_state["langsmith_client"] = Client()
    
st.set_page_config(
    page_title="Agentic RAG System",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)   

st.title("ğŸ¤– Agentic RAG System")
st.markdown("**ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ** - SPRI AI Brief ë¬¸ì„œì™€ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ì§€ëŠ¥í˜• ì§ˆì˜ì‘ë‹µ")

with st.sidebar:
    st.markdown("**ì œì‘ì**: ê¹€ì¬í˜¸")
    st.markdown("**ì‹œìŠ¤í…œ**: Agentic RAG")
    st.markdown("**ê¸°ëŠ¥**:")
    st.markdown("- ğŸ“š SPRI ë¬¸ì„œ ê²€ìƒ‰")
    st.markdown("- ğŸ” ì›¹ ê²€ìƒ‰")
    st.markdown("- ğŸ“Š ì°¨íŠ¸ ìƒì„±")
    st.markdown("- ğŸ’­ ì¼ë°˜ ëŒ€í™”")
    
    st.markdown("---")
    st.markdown("### ğŸ¤– ì—ì´ì „íŠ¸ ì†Œê°œ")
    st.markdown("**Retriever**: SPRI AI Brief ë¬¸ì„œ ê²€ìƒ‰")
    st.markdown("**Researcher**: ì›¹ ê²€ìƒ‰ (TavilySearch)")
    st.markdown("**Coder**: Python ì°¨íŠ¸ ìƒì„±")
    st.markdown("**General LLM**: ì¼ë°˜ ëŒ€í™”")
    st.markdown("**Supervisor**: ì—ì´ì „íŠ¸ ê´€ë¦¬")

# ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìƒíƒœê°’
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ìŠ¤ë ˆë“œ IDë¥¼ì €ì¥í•˜ê¸° ìœ„í•œ ìƒíƒœê°’    
if "thread_id" not in st.session_state:
    st.session_state["thread_id"] = str(uuid4())

# ì§ˆë¬¸ íšŸìˆ˜ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ìƒíƒœê°’
if "question_count" not in st.session_state:
    st.session_state["question_count"] = 0

# SIDE BARìƒì„±
with st.sidebar:
    st.markdown("---")
    st.markdown("**ëŒ€í™” ê´€ë¦¬**")
    
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button(
        "ğŸ”„ ìƒˆë¡œìš´ ì£¼ì œë¡œ ì§ˆë¬¸", type="primary", use_container_width=True
    )
    
    # ì—ì´ì „íŠ¸ ìƒíƒœ í‘œì‹œ
    st.markdown("---")
    st.markdown("### ğŸ“Š í˜„ì¬ ìƒíƒœ")
    st.markdown(f"**ì§ˆë¬¸ ìˆ˜**: {st.session_state['question_count']}")
    st.markdown(f"**ìŠ¤ë ˆë“œ ID**: `{st.session_state['thread_id'][:8]}...`")

def print_messages():
    """ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥"""
    for chat_message in st.session_state["messages"]:
        if chat_message.role == "user":
            st.chat_message(chat_message.role, avatar="ğŸ™â€â™‚ï¸").write(chat_message.content)
        else:
            st.chat_message(chat_message.role, avatar="ğŸ¤–").write(chat_message.content)

def add_message(role, message):
    """ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€"""
    st.session_state["messages"].append(ChatMessage(role=role, content=message))
    
def get_message_history():
    """ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    ret = []
    for chat_message in st.session_state["messages"]:
        if chat_message.role == "user":
            ret.append(HumanMessage(content=chat_message.content))
        else:
            ret.append(AIMessage(content=chat_message.content))
    return ret

# í”¼ë“œë°± ê´€ë ¨ ìƒíƒœê°’
if "feedback" not in st.session_state:
    st.session_state.feedback = {}

if "open_feedback" not in st.session_state:
    st.session_state["open_feedback"] = False

def submit_feedback():
    """í”¼ë“œë°±ì„ LangSmithì— ì œì¶œ"""
    client = st.session_state["langsmith_client"]
    if client:
        feedback = st.session_state.feedback
        run = next(iter(client.list_runs(project_name=LANGSMITH_PROJECT, limit=1)))
        parent_run_id = run.parent_run_ids[0]
        
        for key, value in feedback.items():
            if key in ["ì˜¬ë°”ë¥¸ ë‹µë³€", "ë„ì›€ë¨", "êµ¬ì²´ì„±"]:
                client.create_feedback(parent_run_id, key, score=value)
            elif key == "ì˜ê²¬":
                if value:
                    client.create_feedback(parent_run_id, key, comment=value)

@st.dialog("ğŸ“ ë‹µë³€ í‰ê°€")
def feedback():
    """í”¼ë“œë°± ë‹¤ì´ì–¼ë¡œê·¸"""
    st.session_state["open_feedback"] = False
    
    st.markdown("### ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš” ğŸ™")
    
    eval1 = st.number_input(
        "ğŸ¯ **ì˜¬ë°”ë¥¸ ë‹µë³€** (1:ë§¤ìš° ë‚®ìŒğŸ‘ ~ 5:ë§¤ìš° ë†’ìŒğŸ‘)",
        min_value=1,
        max_value=5,
        value=5,
        help="ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ë„"
    )
    eval2 = st.number_input(
        "ğŸ’¡ **ë„ì›€ë¨** (1:ë§¤ìš° ë¶ˆë§Œì¡±ğŸ‘ ~ 5:ë§¤ìš° ë§Œì¡±ğŸ‘)",
        min_value=1,
        max_value=5,
        value=5,
        help="ë‹µë³€ì´ ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ë„ì›€ì´ ë˜ì—ˆëŠ”ì§€"
    )
    eval3 = st.number_input(
        "ğŸ“‹ **êµ¬ì²´ì„±** (1:ë§¤ìš° ë¶ˆë§Œì¡±ğŸ‘ ~ 5:ë§¤ìš° ë§Œì¡±ğŸ‘)",
        min_value=1,
        max_value=5,
        value=5,
        help="ë‹µë³€ì˜ êµ¬ì²´ì„±ê³¼ ìƒì„¸í•¨"
    )

    comment = st.text_area(
        "ğŸ’¬ **ì˜ê²¬** (ì„ íƒì‚¬í•­)", 
        value="", 
        placeholder="ì¶”ê°€ ì˜ê²¬ì´ë‚˜ ê°œì„ ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”",
        help="ììœ ë¡œìš´ ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”"
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("âŒ ì·¨ì†Œ", use_container_width=True):
            st.rerun()
    with col2:
        if st.button("âœ… ì œì¶œ", type="primary", use_container_width=True):
            with st.spinner("í‰ê°€ë¥¼ ì œì¶œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.feedback = {
                    "ì˜¬ë°”ë¥¸ ë‹µë³€": eval1,
                    "ë„ì›€ë¨": eval2,
                    "êµ¬ì²´ì„±": eval3,
                    "ì˜ê²¬": comment,
                }
                submit_feedback()
            st.success("í‰ê°€ê°€ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤.")
            st.rerun()

# ì´ˆê¸°í™” ë²„íŠ¼ì„ ëˆ„ë¥´ë©´!
if clear_btn:
    st.session_state["messages"] = []
    # thread_idë¥¼ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ì‹œì‘
    st.session_state["thread_id"] = str(uuid4())
    st.session_state["open_feedback"] = False
    st.session_state["question_count"] = 0
    st.success("ğŸ”„ ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥ (ì…ë ¥í•˜ëŠ” ì±„íŒ…ì°½)
user_input = st.chat_input("ğŸ¤” ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”! (SPRI ë¬¸ì„œ, ì›¹ ê²€ìƒ‰, ì°¨íŠ¸ ìƒì„± ë“±)")

# ê·¸ë˜í”„ ì´ˆê¸°í™”
if "graph" not in st.session_state:
    with st.spinner("ğŸ¤– Agentic RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        st.session_state["graph"] = create_graph()
    st.success("âœ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    st.session_state["open_feedback"] = False
    
    # ì§ˆë¬¸ íšŸìˆ˜ ì¦ê°€
    st.session_state["question_count"] += 1
    
    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ í™”ë©´ì— í‘œì‹œ
    st.chat_message("user", avatar="ğŸ™â€â™‚ï¸").write(user_input)
    
    # ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€í™” ê¸°ë¡ì— ë¨¼ì € ì¶”ê°€
    add_message("user", user_input)
    
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ê·¸ë˜í”„ ê°ì²´ë¥¼ ê°€ì ¸ì˜´
    graph = st.session_state["graph"]
    
    # AIë‹µë³€ì„ í‘œì‹œ
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        streamlit_container = st.empty()
        
        # ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ
        response = stream_graph(
            graph,
            user_input,
            streamlit_container,
            thread_id=st.session_state["thread_id"],
            chat_history=get_message_history()
        )
        
        ai_answer = response["answer"]
        used_tools = response.get("used_tools", [])
        
        # ìµœì¢… ë‹µë³€ í‘œì‹œ
        st.write(ai_answer)
        
        # ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ í‘œì‹œ
        if used_tools:
            tool_names = {
                "Retriever": "ğŸ“š SPRI ë¬¸ì„œ ê²€ìƒ‰",
                "Researcher": "ğŸ” ì›¹ ê²€ìƒ‰ (TavilySearch)",
                "Coder": "ğŸ“Š Python ì°¨íŠ¸ ìƒì„±",
                "General LLM": "ğŸ’­ ì¼ë°˜ ëŒ€í™”"
            }
            st.markdown("---")
            st.markdown("**ğŸ› ï¸ ì´ë²ˆ ë‹µë³€ì— ì‚¬ìš©ëœ ë„êµ¬ë“¤:**")
            for tool in used_tools:
                st.markdown(f"â€¢ {tool_names.get(tool, tool)}")
        
        # í‰ê°€ í¼ì„ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ
        eval_container = st.empty()
    
    # 5ë²ˆì§¸ ì§ˆë¬¸ë§ˆë‹¤ë§Œ í‰ê°€ í¼ ìƒì„±
    if st.session_state["question_count"] % 5 == 0:
        with eval_container.form("feedback_form"):
            st.markdown("### ğŸ“ ë‹µë³€ì„ í‰ê°€í•´ ì£¼ì„¸ìš” ğŸ™")
            st.markdown("5ë²ˆì§¸ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì†Œì¤‘í•œ í”¼ë“œë°±ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤!")
            
            # í”¼ë“œë°± ì°½ ì—´ê¸° ìƒíƒœë¥¼ Trueë¡œ ì„¤ì •
            st.session_state["open_feedback"] = True
            
            # í‰ê°€ ì œì¶œ ë²„íŠ¼ ìƒì„±
            submitted = st.form_submit_button("ğŸ“Š í‰ê°€í•˜ê¸°", type="primary")
            if submitted:
                st.success("í‰ê°€ë¥¼ ì œì¶œí•˜ì˜€ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
    
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
    add_message("assistant", ai_answer)
else:
    # 5ë²ˆì§¸ ì§ˆë¬¸ë§ˆë‹¤ë§Œ í”¼ë“œë°± ë‹¤ì´ì–¼ë¡œê·¸ ì—´ê¸°
    if st.session_state["open_feedback"] and st.session_state["question_count"] % 5 == 0:
        feedback()

# í•˜ë‹¨ì— ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ
st.markdown("---")
st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("**í”„ë¡œì íŠ¸**: Agentic RAG")
with col2:
    st.markdown("**ë²„ì „**: 1.0.0")
with col3:
    st.markdown("**ìƒíƒœ**: ğŸŸ¢ ì •ìƒ ì‘ë™")
