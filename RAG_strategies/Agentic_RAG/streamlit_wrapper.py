from dotenv import load_dotenv
load_dotenv()

# Agentic RAG ì‹œìŠ¤í…œ ëª¨ë“ˆë“¤ import
from retriever import QdrantRetrieverFactory, FAISSRetrieverFactory
from graph import create_agentic_rag_graph
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.errors import GraphRecursionError

import streamlit as st

# QdrantRetrieverFactory ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
qs = QdrantRetrieverFactory()
faiss = FAISSRetrieverFactory()

DB_INDEX = "LANGCHAIN_FAISS_DB_INDEX/index.faiss"
# ./jaeho_template/RAG_strategies/Agentic_RAG/LANGCHAIN_FAISS_DB_INDEX
def create_graph():
    """
    Agentic RAG ê·¸ë˜í”„ ìƒì„±
    
    Returns:
        graph: ì»´íŒŒì¼ëœ Agentic RAG ê·¸ë˜í”„
    """
    # Retriever ìƒì„± (FAISS ì¸ë±ìŠ¤ ì‚¬ìš©)
    retriever = faiss.retriever(
        index_path="/RAG_strategies/Agentic_RAG/LANGCHAIN_FAISS_DB_INDEX",
        fetch_k=3
    )
    
    # Agentic RAG ê·¸ë˜í”„ ìƒì„± (ë©”ëª¨ë¦¬ í¬í•¨)
    graph = create_agentic_rag_graph(retriever, use_memory=True)
    
    return graph

# def create_graph():
#     """
#     Agentic RAG ê·¸ë˜í”„ ìƒì„±
    
#     Returns:
#         graph: ì»´íŒŒì¼ëœ Agentic RAG ê·¸ë˜í”„
#     """
#     # Retriever ìƒì„± (SPRI AI Brief ì»¬ë ‰ì…˜ ì‚¬ìš©)
#     retriever = qs.retriever(
#         collection_name="RAG_Example(RAG_strategies)", 
#         fetch_k=3
#     )
    
#     # Agentic RAG ê·¸ë˜í”„ ìƒì„± (ë©”ëª¨ë¦¬ í¬í•¨)
#     graph = create_agentic_rag_graph(retriever, use_memory=True)
    
#     return graph

def stream_graph(app, query, streamlit_container, thread_id, chat_history=None):
    """
    Agentic RAG ê·¸ë˜í”„ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰
    
    Args:
        app: Agentic RAG ê·¸ë˜í”„
        query: ì‚¬ìš©ì ì§ˆë¬¸
        streamlit_container: Streamlit ì»¨í…Œì´ë„ˆ
        thread_id: ìŠ¤ë ˆë“œ ID
        chat_history: ëŒ€í™” ê¸°ë¡ (ì„ íƒì‚¬í•­)
        
    Returns:
        dict: ê·¸ë˜í”„ ì‹¤í–‰ ê²°ê³¼
    """
    config = RunnableConfig(recursion_limit=30, configurable={"thread_id": thread_id})
    
    # chat_historyê°€ Noneì´ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    if chat_history is None:
        chat_history = []
    
    # í˜„ì¬ ì§ˆë¬¸ì„ HumanMessageë¡œ ë³€í™˜
    current_message = HumanMessage(content=query)
    
    # ì…ë ¥ ë©”ì‹œì§€ êµ¬ì„±: ì´ì „ ëŒ€í™” ê¸°ë¡ + í˜„ì¬ ì§ˆë¬¸
    messages = chat_history + [current_message]
    
    inputs = {
        "messages": messages
    }
    
    # ë””ë²„ê¹… ë¡œê·¸ ì œê±°ë¨
    
    # ë…¸ë“œë³„ ìƒíƒœ ë©”ì‹œì§€
    node_actions = {
        "Supervisor": "ğŸ¤– ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
        "Retriever": "ğŸ“š SPRI ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
        "Researcher": "ğŸ” ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
        "Coder": "ğŸ“Š ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
        "General LLM": "ğŸ’­ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
    }
    
    # ì‚¬ìš©ëœ ë„êµ¬ë“¤ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    used_tools = []
    
    try:
        with streamlit_container.status(
            "ğŸ¤” ìƒê°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...", expanded=True
        ) as status:
            final_output = None
            for output in app.stream(inputs, config=config):
                final_output = output  # ë§ˆì§€ë§‰ ì¶œë ¥ ì €ì¥
                for node_name, node_output in output.items():
                    if node_name in node_actions:
                        # ì‚¬ìš©ëœ ë„êµ¬ ì¶”ì  (Supervisor ì œì™¸)
                        if node_name != "Supervisor" and node_name not in used_tools:
                            used_tools.append(node_name)
                        
                        st.write(node_actions[node_name])
                        
                        # íŠ¹ì • ë…¸ë“œì—ì„œ ì¶”ê°€ ì •ë³´ í‘œì‹œ
                        if node_name == "Retriever":
                            st.write("ğŸ“„ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        elif node_name == "Researcher":
                            st.write("ğŸŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
                        elif node_name == "Coder":
                            st.write("ğŸ Python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
                        elif node_name == "General LLM":
                            st.write("âœ¨ ìµœì¢… ë‹µë³€ì„ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            
            # ì‚¬ìš©ëœ ë„êµ¬ë“¤ í‘œì‹œ
            if used_tools:
                tool_names = {
                    "Retriever": "ğŸ“š SPRI ë¬¸ì„œ ê²€ìƒ‰",
                    "Researcher": "ğŸ” ì›¹ ê²€ìƒ‰ (TavilySearch)",
                    "Coder": "ğŸ“Š Python ì°¨íŠ¸ ìƒì„±",
                    "General LLM": "ğŸ’­ ì¼ë°˜ ëŒ€í™”"
                }
                st.write("---")
                st.write("**ğŸ› ï¸ ì‚¬ìš©ëœ ë„êµ¬ë“¤:**")
                for tool in used_tools:
                    st.write(f"â€¢ {tool_names.get(tool, tool)}")
            
            # ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë°ì´ ì™„ë£Œëœ í›„ì—ë§Œ "ë‹µë³€ ì™„ë£Œ" í‘œì‹œ
            status.update(label="âœ… ë‹µë³€ ì™„ë£Œ!", state="complete", expanded=False)
                
    except GraphRecursionError as e:
        st.error(f"ì¬ê·€ í•œê³„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤: {e}")
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì´ ë„ˆë¬´ ë³µì¡í•´ì„œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    # ìµœì¢… ë‹µë³€ ì¶”ì¶œ
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì— ìƒì„±ëœ ìµœì¢… ì¶œë ¥ì—ì„œ ë‹µë³€ ì¶”ì¶œ
        if final_output:
            # ë§ˆì§€ë§‰ ì¶œë ¥ì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ
            for node_name, node_output in final_output.items():
                if hasattr(node_output, 'get') and 'messages' in node_output:
                    messages = node_output['messages']
                    # AI ë©”ì‹œì§€ ì°¾ê¸°
                    ai_messages = [msg for msg in messages if hasattr(msg, 'type') and msg.type == 'ai']
                    if ai_messages:
                        answer = ai_messages[-1].content
                        return {"answer": answer, "used_tools": used_tools}
        
        # ìœ„ ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ë˜í”„ ìƒíƒœì—ì„œ ì¶”ì¶œ
        final_state = app.get_state(config={"configurable": {"thread_id": thread_id}})
        messages = final_state.values.get("messages", [])
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°
        ai_messages = [msg for msg in messages if hasattr(msg, 'type') and msg.type == 'ai']
        if ai_messages:
            answer = ai_messages[-1].content
        else:
            # AI ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‚¬ìš©
            answer = messages[-1].content if messages else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        return {"answer": answer, "used_tools": used_tools}
        
    except Exception as e:
        st.error(f"ë‹µë³€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "used_tools": used_tools}
