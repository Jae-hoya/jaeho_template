import streamlit as st
from uuid import uuid4

from dotenv import load_dotenv

from streamlit_wrapper import create_graph, stream_graph

from langchain_teddynote import logging
from langsmith import Client
from langchain_core.messages import HumanMessage, AIMessage, ChatMessage

import requests
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

load_dotenv()

LANGSMITH_PROJECT = "Agentic RAG System"
FASTAPI_SERVER_URL = "http://localhost:8000"  # FastAPI ì„œë²„ URL

logging.langsmith(LANGSMITH_PROJECT)

NAMESPACE = "agentic_rag"

# ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ í’€
if "thread_pool" not in st.session_state:
    st.session_state["thread_pool"] = ThreadPoolExecutor(max_workers=5)

if "langsmith_client" not in st.session_state:
    st.session_state["langsmith_client"] = Client()
    
st.set_page_config(
    page_title="Agentic RAG System",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)   

st.title("ğŸ¤– Agentic RAG System")
st.markdown("**ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ** - SPRI AI Brief ë¬¸ì„œì™€ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ì§€ëŠ¥í˜• ì§ˆì˜ì‘ë‹µ")

with st.sidebar:
    st.markdown("**ì œì‘ì**: ê¹€ì¬í˜¸")
    st.markdown("**ì‹œìŠ¤í…œ**: Agentic RAG")
    st.markdown("**ê¸°ëŠ¥**:")
    st.markdown("- ğŸ“š SPRI ë¬¸ì„œ ê²€ìƒ‰")
    st.markdown("- ğŸ” ì›¹ ê²€ìƒ‰")
    st.markdown("- ğŸ“Š ì°¨íŠ¸ ìƒì„±")
    st.markdown("- ğŸ’­ ì¼ë°˜ ëŒ€í™”")
    
    st.markdown("---")
    st.markdown("### ğŸ¤– ì—ì´ì „íŠ¸ ì†Œê°œ")
    st.markdown("**Retriever**: SPRI AI Brief ë¬¸ì„œ ê²€ìƒ‰")
    st.markdown("**Researcher**: ì›¹ ê²€ìƒ‰ (TavilySearch)")
    st.markdown("**Coder**: Python ì°¨íŠ¸ ìƒì„±")
    st.markdown("**General LLM**: ì¼ë°˜ ëŒ€í™”")
    st.markdown("**Supervisor**: ì—ì´ì „íŠ¸ ê´€ë¦¬")

# ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìƒíƒœê°’
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ìŠ¤ë ˆë“œ IDë¥¼ì €ì¥í•˜ê¸° ìœ„í•œ ìƒíƒœê°’    
if "thread_id" not in st.session_state:
    st.session_state["thread_id"] = str(uuid4())

# ì§ˆë¬¸ íšŸìˆ˜ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ìƒíƒœê°’
if "question_count" not in st.session_state:
    st.session_state["question_count"] = 0

# SIDE BARìƒì„±
with st.sidebar:
    st.markdown("---")
    st.markdown("**ëŒ€í™” ê´€ë¦¬**")
    
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button(
        "ğŸ”„ ìƒˆë¡œìš´ ì£¼ì œë¡œ ì§ˆë¬¸", type="primary", use_container_width=True
    )
    
    # ì—ì´ì „íŠ¸ ìƒíƒœ í‘œì‹œ
    st.markdown("---")
    st.markdown("### ğŸ“Š í˜„ì¬ ìƒíƒœ")
    st.markdown(f"**ì§ˆë¬¸ ìˆ˜**: {st.session_state['question_count']}")
    st.markdown(f"**ìŠ¤ë ˆë“œ ID**: `{st.session_state['thread_id'][:8]}...`")

def print_messages():
    """ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥"""
    for chat_message in st.session_state["messages"]:
        if chat_message.role == "user":
            st.chat_message(chat_message.role, avatar="ğŸ™â€â™‚ï¸").write(chat_message.content)
        else:
            st.chat_message(chat_message.role, avatar="ğŸ¤–").write(chat_message.content)

def add_message(role, message):
    """ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€"""
    st.session_state["messages"].append(ChatMessage(role=role, content=message))
    
def get_message_history():
    """ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    ret = []
    for chat_message in st.session_state["messages"]:
        if chat_message.role == "user":
            ret.append(HumanMessage(content=chat_message.content))
        else:
            ret.append(AIMessage(content=chat_message.content))
    return ret

# í”¼ë“œë°± ê´€ë ¨ ìƒíƒœê°’
if "feedback" not in st.session_state:
    st.session_state.feedback = {}

if "open_feedback" not in st.session_state:
    st.session_state["open_feedback"] = False

def add_conversation_to_buffer(user_message: str, ai_response: str, used_tools: list = None):
    """ëŒ€í™”ë¥¼ thread_idë³„ë¡œ ê°™ì€ íŒŒì¼ì— ì €ì¥"""
    thread_id = st.session_state.get("thread_id", str(uuid4()))
    question_count = st.session_state.get("question_count", 0)
    
    conversation_data = {
        "thread_id": thread_id,
        "question_count": question_count,
        "user_message": user_message,
        "ai_response": ai_response,
        "used_tools": used_tools or [],
        "timestamp": datetime.now().isoformat()
    }
    
    # thread_idë³„ë¡œ ê°™ì€ íŒŒì¼ì— ì €ì¥
    submit_conversation_by_thread_async(conversation_data)

def submit_conversation_by_thread_async(conversation_data):
    """thread_idë³„ë¡œ ê°™ì€ íŒŒì¼ì— ëŒ€í™”ë¥¼ ì €ì¥"""
    def _send_by_thread():
        try:
            response = requests.post(
                f"{FASTAPI_SERVER_URL}/conversation/thread",
                json=conversation_data,
                timeout=5
            )
            
            if response.status_code == 200:
                print(f"thread_idë³„ ì €ì¥ ì„±ê³µ: thread_id={conversation_data['thread_id']}, question_count={conversation_data['question_count']}")
            else:
                print(f"thread_idë³„ ì €ì¥ ì‹¤íŒ¨: {response.status_code}")
                
        except Exception as e:
            print(f"thread_idë³„ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
    st.session_state["thread_pool"].submit(_send_by_thread)

def submit_feedback_to_fastapi_async(feedback_data):
    """ë¹„ë™ê¸°ë¡œ í”¼ë“œë°± ë°ì´í„°ë¥¼ FastAPI ì„œë²„ì— ì „ì†¡"""
    # ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì„¸ì…˜ ìƒíƒœ ê°’ì„ ê°€ì ¸ì˜´
    thread_id = st.session_state.get("thread_id", str(uuid4()))
    question_count = st.session_state.get("question_count", 0)
    
    def _send_feedback():
        try:
            # feedback_scoresì—ì„œ "ì˜ê²¬" í‚¤ë¥¼ ì œê±°í•˜ê³  ë³„ë„ë¡œ ì²˜ë¦¬
            feedback_scores = {k: v for k, v in feedback_data.items() if k != "ì˜ê²¬"}
            
            payload = {
                "thread_id": thread_id,
                "question_count": question_count,
                "feedback_scores": feedback_scores,
                "timestamp": datetime.now().isoformat()
            }
            
            # ì˜ê²¬ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if "ì˜ê²¬" in feedback_data and feedback_data["ì˜ê²¬"]:
                payload["comment"] = feedback_data["ì˜ê²¬"]
            
            print(f"ì „ì†¡í•  í”¼ë“œë°± ë°ì´í„°: {payload}")  # ë””ë²„ê¹…ìš©
            
            response = requests.post(
                f"{FASTAPI_SERVER_URL}/feedback",
                json=payload,
                timeout=5
            )
            
            if response.status_code == 200:
                print("FastAPI ì„œë²„ë¡œ í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"FastAPI ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                print(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
                
        except Exception as e:
            print(f"í”¼ë“œë°± ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
    st.session_state["thread_pool"].submit(_send_feedback)

def submit_session_summary_async():
    """ì„¸ì…˜ ì „ì²´ ìš”ì•½ì„ FastAPI ì„œë²„ì— ì „ì†¡"""
    if not st.session_state.get("messages", []):
        return
    
    thread_id = st.session_state.get("thread_id", str(uuid4()))
    question_count = st.session_state.get("question_count", 0)
    
    def _send_summary():
        try:
            # ì „ì²´ ëŒ€í™” ë‚´ìš© ìš”ì•½
            conversation_summary = {
                "thread_id": thread_id,
                "total_questions": question_count,
                "session_duration": 0,  # ì„¸ì…˜ ì§€ì† ì‹œê°„ ê³„ì‚° ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                "conversation_count": len(st.session_state.get("messages", [])),
                "timestamp": datetime.now().isoformat()
            }
            
            response = requests.post(
                f"{FASTAPI_SERVER_URL}/session/summary",
                json=conversation_summary,
                timeout=10
            )
            
            if response.status_code == 200:
                print("ì„¸ì…˜ ìš”ì•½ ì „ì†¡ ì„±ê³µ")
            else:
                print(f"ì„¸ì…˜ ìš”ì•½ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                
        except Exception as e:
            print(f"ì„¸ì…˜ ìš”ì•½ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
    st.session_state["thread_pool"].submit(_send_summary)

def submit_feedback():
    """í”¼ë“œë°±ì„ LangSmithì™€ FastAPIì— ì œì¶œ"""
    client = st.session_state["langsmith_client"]
    feedback = st.session_state.feedback
    
    # LangSmithë¡œ í”¼ë“œë°± ì „ì†¡ (ë™ê¸°)
    if client:
        try:
            run = next(iter(client.list_runs(project_name=LANGSMITH_PROJECT, limit=1)))
            parent_run_id = run.parent_run_ids[0]
            
            for key, value in feedback.items():
                if key in ["ì˜¬ë°”ë¥¸ ë‹µë³€", "ë„ì›€ë¨", "êµ¬ì²´ì„±"]:
                    client.create_feedback(parent_run_id, key, score=value)
                elif key == "ì˜ê²¬":
                    if value:
                        client.create_feedback(parent_run_id, key, comment=value)
        except Exception as e:
            st.error(f"LangSmith í”¼ë“œë°± ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
    
    # FastAPI ì„œë²„ë¡œ í”¼ë“œë°± ì „ì†¡ (ë¹„ë™ê¸°)
    submit_feedback_to_fastapi_async(feedback)
    st.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤. (ë¹„ë™ê¸° ì²˜ë¦¬ ì¤‘)")

@st.dialog("ğŸ“ ë‹µë³€ í‰ê°€")
def feedback():
    """í”¼ë“œë°± ë‹¤ì´ì–¼ë¡œê·¸"""
    st.session_state["open_feedback"] = False
    
    st.markdown("### ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš” ğŸ™")
    
    eval1 = st.number_input(
        "ğŸ¯ **ì˜¬ë°”ë¥¸ ë‹µë³€** (1:ë§¤ìš° ë‚®ìŒğŸ‘ ~ 5:ë§¤ìš° ë†’ìŒğŸ‘)",
        min_value=1,
        max_value=5,
        value=5,
        help="ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ë„"
    )
    eval2 = st.number_input(
        "ğŸ’¡ **ë„ì›€ë¨** (1:ë§¤ìš° ë¶ˆë§Œì¡±ğŸ‘ ~ 5:ë§¤ìš° ë§Œì¡±ğŸ‘)",
        min_value=1,
        max_value=5,
        value=5,
        help="ë‹µë³€ì´ ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ë„ì›€ì´ ë˜ì—ˆëŠ”ì§€"
    )
    eval3 = st.number_input(
        "ğŸ“‹ **êµ¬ì²´ì„±** (1:ë§¤ìš° ë¶ˆë§Œì¡±ğŸ‘ ~ 5:ë§¤ìš° ë§Œì¡±ğŸ‘)",
        min_value=1,
        max_value=5,
        value=5,
        help="ë‹µë³€ì˜ êµ¬ì²´ì„±ê³¼ ìƒì„¸í•¨"
    )

    comment = st.text_area(
        "ğŸ’¬ **ì˜ê²¬** (ì„ íƒì‚¬í•­)", 
        value="", 
        placeholder="ì¶”ê°€ ì˜ê²¬ì´ë‚˜ ê°œì„ ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”",
        help="ììœ ë¡œìš´ ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”"
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("âŒ ì·¨ì†Œ", use_container_width=True):
            st.rerun()
    with col2:
        if st.button("âœ… ì œì¶œ", type="primary", use_container_width=True):
            with st.spinner("í‰ê°€ë¥¼ ì œì¶œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.feedback = {
                    "ì˜¬ë°”ë¥¸ ë‹µë³€": eval1,
                    "ë„ì›€ë¨": eval2,
                    "êµ¬ì²´ì„±": eval3,
                    "ì˜ê²¬": comment,
                }
                submit_feedback()
            st.success("í‰ê°€ê°€ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤.")
            st.rerun()

# ì´ˆê¸°í™” ë²„íŠ¼ì„ ëˆ„ë¥´ë©´!
if clear_btn:
    # ì„¸ì…˜ ì¢…ë£Œ ì‹œ ìš”ì•½ ì „ì†¡
    submit_session_summary_async()
    
    # ìƒíƒœ ì´ˆê¸°í™”
    st.session_state["messages"] = []
    st.session_state["thread_id"] = str(uuid4())
    st.session_state["open_feedback"] = False
    st.session_state["question_count"] = 0
    st.success("ğŸ”„ ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥ (ì…ë ¥í•˜ëŠ” ì±„íŒ…ì°½)
user_input = st.chat_input("ğŸ¤” ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”! (SPRI ë¬¸ì„œ, ì›¹ ê²€ìƒ‰, ì°¨íŠ¸ ìƒì„± ë“±)")

# ê·¸ë˜í”„ ì´ˆê¸°í™”
if "graph" not in st.session_state:
    with st.spinner("ğŸ¤– Agentic RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        st.session_state["graph"] = create_graph()
    st.success("âœ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    st.session_state["open_feedback"] = False
    
    # ì§ˆë¬¸ íšŸìˆ˜ ì¦ê°€
    st.session_state["question_count"] += 1
    
    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ í™”ë©´ì— í‘œì‹œ
    st.chat_message("user", avatar="ğŸ™â€â™‚ï¸").write(user_input)
    
    # ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€í™” ê¸°ë¡ì— ë¨¼ì € ì¶”ê°€
    add_message("user", user_input)
    
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ê·¸ë˜í”„ ê°ì²´ë¥¼ ê°€ì ¸ì˜´
    graph = st.session_state["graph"]
    
    # AIë‹µë³€ì„ í‘œì‹œ
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        streamlit_container = st.empty()
        
        # ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ
        response = stream_graph(
            graph,
            user_input,
            streamlit_container,
            thread_id=st.session_state["thread_id"],
            chat_history=get_message_history()
        )
        
        ai_answer = response["answer"]
        used_tools = response.get("used_tools", [])
        
        # ìµœì¢… ë‹µë³€ í‘œì‹œ
        st.write(ai_answer)
        
        # ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ í‘œì‹œ
        if used_tools:
            tool_names = {
                "Retriever": "ğŸ“š SPRI ë¬¸ì„œ ê²€ìƒ‰",
                "Researcher": "ğŸ” ì›¹ ê²€ìƒ‰ (TavilySearch)",
                "Coder": "ğŸ“Š Python ì°¨íŠ¸ ìƒì„±",
                "General LLM": "ğŸ’­ ì¼ë°˜ ëŒ€í™”"
            }
            st.markdown("---")
            st.markdown("**ğŸ› ï¸ ì´ë²ˆ ë‹µë³€ì— ì‚¬ìš©ëœ ë„êµ¬ë“¤:**")
            for tool in used_tools:
                st.markdown(f"â€¢ {tool_names.get(tool, tool)}")
        
        # í‰ê°€ í¼ì„ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ
        eval_container = st.empty()
    
    # 5ë²ˆì§¸ ì§ˆë¬¸ë§ˆë‹¤ë§Œ í‰ê°€ í¼ ìƒì„±
    if st.session_state["question_count"] % 5 == 0:
        with eval_container.form("feedback_form"):
            st.markdown("### ğŸ“ ë‹µë³€ì„ í‰ê°€í•´ ì£¼ì„¸ìš” ğŸ™")
            st.markdown("5ë²ˆì§¸ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì†Œì¤‘í•œ í”¼ë“œë°±ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤!")
            
            # í”¼ë“œë°± ì°½ ì—´ê¸° ìƒíƒœë¥¼ Trueë¡œ ì„¤ì •
            st.session_state["open_feedback"] = True
            
            # í‰ê°€ ì œì¶œ ë²„íŠ¼ ìƒì„±
            submitted = st.form_submit_button("ğŸ“Š í‰ê°€í•˜ê¸°", type="primary")
            if submitted:
                st.success("í‰ê°€ë¥¼ ì œì¶œí•˜ì˜€ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
    
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
    add_message("assistant", ai_answer)
    
    # ëŒ€í™”ë¥¼ thread_idë³„ë¡œ ê°™ì€ íŒŒì¼ì— ì €ì¥
    add_conversation_to_buffer(user_input, ai_answer, used_tools)
else:
    # 5ë²ˆì§¸ ì§ˆë¬¸ë§ˆë‹¤ë§Œ í”¼ë“œë°± ë‹¤ì´ì–¼ë¡œê·¸ ì—´ê¸°
    if st.session_state["open_feedback"] and st.session_state["question_count"] % 5 == 0:
        feedback()

# í•˜ë‹¨ì— ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ
st.markdown("---")
st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("**í”„ë¡œì íŠ¸**: Agentic RAG")
with col2:
    st.markdown("**ë²„ì „**: 1.0.0")
with col3:
    st.markdown("**ìƒíƒœ**: ğŸŸ¢ ì •ìƒ ì‘ë™")
