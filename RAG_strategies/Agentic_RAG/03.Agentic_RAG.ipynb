{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317b3ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import QdrantRetrieverFactory\n",
    "\n",
    "qs = QdrantRetrieverFactory()\n",
    "\n",
    "retriever = qs.retriever(collection_name=\"RAG_Example(RAG_strategies)\", fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41aa7b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docling_outputs\\\\SPRi AI Brief_8월호_산업동향_F.md', '_id': '99fab946-a7a5-44fc-a827-38cba5e9b3ca', '_collection_name': 'RAG_Example(RAG_strategies)'}, page_content=\"- n AI 이미지 생성 플랫폼 미드저니(Midjourney)가 2025년 6월 19일 비디오 생성 모델 'V1'을 출시\\n- V1은 이미지를 동영상으로 변환하는 모델로, 미드저니 플랫폼에서 제작된 이미지나 외부 이미지를 바탕으로 동영상을 생성하며, '자동' 설정 시에는 모션 프롬프트가 자동으로 생성되고 '수동' 설정을 선택하면 사용자 지시에 따라 사물이나 장면의 움직임을 생성\\n- 사용자는 움직임 강도를 피사체와 카메라가 모두 움직이는 '하이 모션(High Motion)'과 카메라는 거의 고정되어 있고 피사체가 천천히 움직이도록 연출 '로우 모션(Low Motion)' 중에서 선택 가능\\n- 웹 전용 모델인 V1은 1회 동영상 생성 작업으로 5초 길이의 동영상 4개를 제작하며, 생성된 동영상은 한 번에 4초씩 최대 4회까지 영상 길이를 확장할 수 있도록 허용\"),\n",
       " Document(metadata={'source': 'docling_outputs\\\\SPRi AI Brief_8월호_산업동향_F.md', '_id': '3b53a337-de9e-47b0-a2f4-eaedb4519aee', '_collection_name': 'RAG_Example(RAG_strategies)'}, page_content=\"<!-- image -->\\n\\n## 기업 ･ 산업\\n\\n<!-- image -->\\n\\n## 미드저니, 첫 번째 비디오 생성 AI 모델 'V1' 출시\\n\\n## KEY Contents\\n\\n- n 미드저니가 1회 작업으로 5초 길이의 동영상 4개를 제작할 수 있는 비디오 생성 모델 'V1'을 출시하고 여타 비디오 생성 모델보다 25배 이상 저렴한 가격을 책정했다고 강조\\n- n 미드저니는 실시간 오픈월드 시뮬레이션이 가능한 AI 모델 개발을 궁극적 목표로 제시하고, 2026년에 3D 모델과 실시간 처리 모델을 출시한 뒤 각 모델을 하나로 통합할 계획이라고 설명\\n\\n## £ 'V1', 미드저니에서 생성한 이미지나 외부 이미지를 동영상으로 변환\"),\n",
       " Document(metadata={'source': 'docling_outputs\\\\SPRi AI Brief_8월호_산업동향_F.md', '_id': '1517467d-f582-48df-a032-a9cff3d84d35', '_collection_name': 'RAG_Example(RAG_strategies)'}, page_content=\"|               | ∙ EU 집행위원회, 「AI 법」의 범용 AI 관련 실천 강령과 지침 발표       |   6 |\\n| 기업 ･ 산업   | ∙ 미드저니, 첫 번째 비디오 생성 AI 모델 'V1' 출시                     |   8 |\\n|               | ∙ 바이두,10년만에AI기반으로검색서비스대폭개편                         |   9 |\\n|               | ∙ 문샷 AI, 에이전트 기능 지원하는 '키미 K2'오픈소스 공개              |  10 |\\n|               | ∙ xAI, 차세대 AI 모델 '그록 4'공개 및 정부 AI 시장 진출               |  11 |\\n|               | ∙ 퍼플렉시티, AI 에이전트 탑재한 웹 브라우저 '코멧'출시               |  12 |\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"미드저니\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bf9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag import rag\n",
    "\n",
    "rag_chain = rag(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e628cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"미드저니(Midjourney)는 AI 이미지 생성 플랫폼으로, 2025년 6월 19일 비디오 생성 모델 'V1'을 출시했습니다. V1은 미드저니에서 생성한 이미지나 외부 이미지를 바탕으로 5초 길이의 동영상 4개를 한 번에 제작할 수 있으며, 동영상 길이는 최대 4초씩 4회까지 확장 가능합니다. 사용자는 '하이 모션(High Motion)'과 '로우 모션(Low Motion)' 중 움직임 강도를 선택할 수 있고, 자동 또는 수동 모션 프롬프트 설정이 가능합니다. 미드저니는 2026년에 3D 모델과 실시간 처리 모델을 출시해 통합할 계획이며, V1은 여타 비디오 생성 모델보다 25배 이상 저렴한 가격을 책정했습니다.\\n\\n**Source**  \\n- docling_outputs\\\\SPRi AI Brief_8월호_산업동향_F.md (p.8)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\": \"미드저니\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d70dbd",
   "metadata": {},
   "source": [
    "# 상태 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8519f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Optional\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "# create_react_agent에서는 messages를 키로 사용한다.\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    next: Optional[str]  # 다음에 실행할 노드를 지정하는 필드 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136753eb",
   "metadata": {},
   "source": [
    "# create_retriever_tool\n",
    "\n",
    "retriever를 하나의 도구로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc5e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever=retriever, name=\"retriever\",\n",
    "                                       description=\"Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI trends. The document is published on Dec 2025\",\n",
    "                                       document_prompt=PromptTemplate.from_template(\n",
    "                                           \"<document><content>{page_content}</content><metadata><source>{source}</source><page></page></metadata></document>\"\n",
    "                                            )\n",
    "                                       )\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc0a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"에이전틱 RAG의 장점은?\"\n",
    "# result = retriever_tool.invoke(query)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9f7cb",
   "metadata": {},
   "source": [
    "# create_react_agent: Agent생성\n",
    "\n",
    "create_react_agent는, messages로 대화를 주고 받는게 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac71483",
   "metadata": {},
   "source": [
    "### retriever_agent 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7dfb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import make_system_prompt\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "retriever_agent = create_react_agent(llm, tools=tools,\n",
    "                                    state_modifier=make_system_prompt(\n",
    "                                    \"\"\"You are a specialized research agent focused on retrieving and analyzing information from SPRI AI Brief documents.\n",
    "                                    \n",
    "                                    Your primary responsibilities:\n",
    "                                    1. Search through SPRI AI Brief PDF documents using the retriever tool\n",
    "                                    2. Find relevant, authoritative information about AI trends, technologies, and industry developments\n",
    "                                    3. Provide detailed, well-sourced answers based on the retrieved documents\n",
    "                                    4. Always cite your sources and provide context for the information you share\n",
    "                                    \n",
    "                                    You work collaboratively with other agents:\n",
    "                                    - Researcher agent: Handles web-based research and current information\n",
    "                                    - Coder agent: Creates visualizations and charts based on your findings\n",
    "                                    \n",
    "                                    When retrieving information:\n",
    "                                    - Use specific, targeted search queries\n",
    "                                    - Look for the most relevant and recent information\n",
    "                                    - Provide comprehensive answers with proper context\n",
    "                                    - Always mention the source of your information\n",
    "                                    \n",
    "                                    Remember: You can ONLY use the retriever tool to search SPRI documents. For other types of research, coordinate with the Researcher agent.\"\"\"), \n",
    "                                    checkpointer=memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdac002",
   "metadata": {},
   "source": [
    "# retriever_node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f2da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def retriever_node(state: AgentState) -> AgentState:\n",
    "    # invoke 시 분리\n",
    "    result = retriever_agent.invoke(\n",
    "        {\"messages\": state[\"messages\"]}, \n",
    "    )\n",
    "\n",
    "    last_ai = [m for m in result[\"messages\"] if m.type == \"ai\"][-1]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=last_ai.content, name=\"retriever\")],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7e941",
   "metadata": {},
   "source": [
    "### Research Agent 생성\n",
    "\n",
    "TavilySearch 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6105a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "tavily_tool = TavilySearch(max_results=5)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "research_agent = create_react_agent(llm, tools=[tavily_tool],\n",
    "                                    state_modifier=make_system_prompt(\n",
    "                                        \"You can only do research. You are working with a chart generator colleague.\"\n",
    "                                    ),\n",
    "                                    checkpointer=MemorySaver()\n",
    "                                    )\n",
    "def research_node(state: MessagesState) -> MessagesState:\n",
    "    result = research_agent.invoke(\n",
    "        {\"messages\": state[\"messages\"]},\n",
    "    )\n",
    "    last_message = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"research\"\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [last_message],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0ea2a",
   "metadata": {},
   "source": [
    "# Chart Generator Agent\n",
    "PythonREPL 도구를 사용하여 차트를 생성하는 에이전트를 생성합니다. 이 에이전트를 차트를 생성하는 데 사용합니다.\n",
    "\n",
    "파이썬 repl 도구를 새로 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cffcd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "# Python 코드를 실행하는 도구 정의\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        # 주어진 코드를 Python REPL에서 실행하고 결과 반환\n",
    "        result = python_repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute code. Error: {repr(e)}\"\n",
    "    # 실행 성공 시 결과와 함께 성공 메시지 반환\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861d66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_system_prompt = \"\"\"\n",
    "Be sure to use the following font in your code for visualization.\n",
    "\n",
    "##### 폰트 설정 #####\n",
    "import platform\n",
    "\n",
    "# OS 판단\n",
    "current_os = platform.system()\n",
    "\n",
    "if current_os == \"Windows\":\n",
    "    # Windows 환경 폰트 설정\n",
    "    font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 맑은 고딕 폰트 경로\n",
    "    fontprop = fm.FontProperties(fname=font_path, size=12)\n",
    "    plt.rc(\"font\", family=fontprop.get_name())\n",
    "elif current_os == \"Darwin\":  # macOS\n",
    "    # Mac 환경 폰트 설정\n",
    "    plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "else:  # Linux 등 기타 OS\n",
    "    # 기본 한글 폰트 설정 시도\n",
    "    try:\n",
    "        plt.rcParams[\"font.family\"] = \"NanumGothic\"\n",
    "    except:\n",
    "        print(\"한글 폰트를 찾을 수 없습니다. 시스템 기본 폰트를 사용합니다.\")\n",
    "\n",
    "##### 마이너스 폰트 깨짐 방지 #####\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 마이너스 폰트 깨짐 방지\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Chart Generator Agent 생성\n",
    "coder_agent = create_react_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    state_modifier=code_system_prompt,\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f783045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coder_node(state: MessagesState) -> MessagesState:\n",
    "    result = coder_agent.invoke(state)\n",
    "\n",
    "    # 마지막 메시지를 HumanMessage 로 변환\n",
    "    last_message = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"coder\",\n",
    "        # config = state[\"config\"]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        # share internal message history of chart agent with other agents\n",
    "        \"messages\": [last_message],\n",
    "        # \"config\": state[\"config\"]    \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164afb4",
   "metadata": {},
   "source": [
    "# 일반질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fdb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Agent 생성 (react_agent로 변경)\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# General Agent를 react_agent로 생성\n",
    "general_agent = create_react_agent(\n",
    "    llm, \n",
    "    tools=[],  # 도구 없음 (일반적인 대화만)\n",
    "    state_modifier=make_system_prompt(\n",
    "        \"You are a helpful general assistant. You can answer general questions, \"\n",
    "        \"have conversations, and provide information. You work with other specialized agents: \"\n",
    "        \"- Retriever agent: For searching SPRI documents \"\n",
    "        \"- Researcher agent: For web research \"\n",
    "        \"- Coder agent: For creating charts and visualizations \"\n",
    "        \"If you need specialized information, coordinate with the appropriate agent.\"\n",
    "    ),\n",
    "    checkpointer=MemorySaver()\n",
    ")\n",
    "\n",
    "def general_node(state: MessagesState) -> MessagesState:\n",
    "    # react_agent 사용\n",
    "    result = general_agent.invoke(\n",
    "        {\"messages\": state[\"messages\"]},\n",
    "    )\n",
    "    \n",
    "    # 마지막 메시지를 HumanMessage로 변환\n",
    "    last_message = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"general\",\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [last_message],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ab5c9",
   "metadata": {},
   "source": [
    "# Agent Supervisor 생성\n",
    "에이전트를 관리 감독하는 감독자 에이전트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2eb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Retriever\", \"Researcher\", \"Coder\", \"General LLM\"]\n",
    "\n",
    "options_for_next = [\"FINISH\"] + members\n",
    "\n",
    "class RouteResponse(BaseModel):\n",
    "    next: Literal[*options_for_next]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb172e",
   "metadata": {},
   "source": [
    "partial은 olptions와 members를 채우는 값인데, 어떻게 채워야 하는지 고정값이 정해지는것이다.\n",
    "\n",
    "따라서, `invoke`할때 따로 넣어주지 않아도 되는 값이다.\n",
    "\n",
    "이중에서 `options_for_next` 중에 하나를 뽑게 되는 prompt, chain이 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a01270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# # 시스템 프롬프트 정의: 작업자 간의 대화를 관리하는 감독자 역할\n",
    "# system_prompt = (\n",
    "#     \"You are a supervisor tasked with managing a conversation between the\"\n",
    "#     \" following workers:  {members}. Given the following user request,\"\n",
    "#     \" respond with the worker to act next. Each worker will perform a\"\n",
    "#     \" task and respond with their results and status.\"\n",
    "    \n",
    "#     \" CRITICAL RULE: If a question comes up, you MUST answer it. Don't just send it to FINISH!\"\n",
    "    \n",
    "#     \" IMPORTANT FINISH CONDITIONS:\"\n",
    "#     \" - FINISH only when the user's question has been fully answered\"\n",
    "#     \" - FINISH only when at least one worker has provided a complete response\"\n",
    "#     \" - FINISH only when no additional information or action is needed\"\n",
    "#     \" - Do NOT FINISH if the response is incomplete or needs clarification\"\n",
    "#     \" - Do NOT FINISH if the user's question is not answered\"\n",
    "#     \" WORKER SELECTION RULES:\"\n",
    "#     \" - You must select at least one worker before considering FINISH\"\n",
    "#     \" - Do not select FINISH immediately - always try a worker first\"\n",
    "#     \" - Do not select the same worker more than 2 times in a row\"\n",
    "#     \" - If a worker's response is incomplete, select another appropriate worker\"\n",
    "# )\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", system_prompt),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"Given the conversation above, who should act next?\"\n",
    "#             \"Or should we FINISH? Select one of: {options}\"\n",
    "            \n",
    "#             \" CRITICAL: You MUST answer the user's question before selecting FINISH!\"\n",
    "            \n",
    "#             \" DECISION CRITERIA:\"\n",
    "#             \" - If the user's question is fully answered with complete information, select FINISH\"\n",
    "#             \" - If the response is incomplete or needs more information, select an appropriate worker\"\n",
    "#             \" - If a worker has provided a complete response, consider FINISH\"\n",
    "#             \" - If a worker's response is insufficient, select another worker\"\n",
    "#             \" - NEVER select FINISH if the user's question is not answered\"\n",
    "            \n",
    "#             \" IMPORTANT RULES:\"\n",
    "#             \" - Do not select the same {members} more than 2 times in a row\"\n",
    "#             \" - You must select at least one {members} before considering FINISH\"\n",
    "#             \" - Only select FINISH when the task is truly complete\"\n",
    "#         )\n",
    "#     ]\n",
    "# ).partial(options=str(options_for_next), members=\", \".join(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "742eb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 시스템 프롬프트 정의: 작업자 간의 대화를 관리하는 감독자 역할\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    "    \" If a worker has already provided a response, consider if FINISH is appropriate.\"\n",
    "    \" task and respond with their results and status.\"\n",
    "    \" You must select at least one worker before considering FINISH.\"\n",
    "    \" Do not select FINISH immediately - always try a worker first.\"\n",
    "    \" Do not select the same worker({members}) more than once times in a row.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \"Or should we FINISH? Select one of: {options}\"\n",
    "            \" IMPORTANT: Do not select the same worker({members}) more than once times in a row.\"\n",
    "            \" IMPORTANT: You must select at least one worker({members}) before considering FINISH.\"\n",
    "            \" If a worker has already provided a response, consider FINISH.\"\n",
    "        )\n",
    "    ]\n",
    ").partial(options=str(options_for_next), members=\", \".join(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a92413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state):\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "    supervisor_chain = prompt | llm.with_structured_output(RouteResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7283c9",
   "metadata": {},
   "source": [
    "# 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f01c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 생성\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 그래프에 노드 추가\n",
    "workflow.add_node(\"Retriever\", retriever_node)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", coder_node)\n",
    "workflow.add_node(\"General LLM\", general_node)\n",
    "\n",
    "workflow.add_node(\"Supervisor\", supervisor_agent)\n",
    "\n",
    "\n",
    "# 멤버 노드 > Supervisor 노드로 엣지 추가\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"Supervisor\")\n",
    "\n",
    "# 조건부 엣지 추가 (\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "\n",
    "\n",
    "def get_next(state):\n",
    "    return state[\"next\"]\n",
    "\n",
    "\n",
    "# Supervisor 노드에서 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\"Supervisor\", get_next, conditional_map)\n",
    "\n",
    "# 시작점\n",
    "workflow.add_edge(START, \"Supervisor\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d3ed317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"next\":\"General LLM\"}\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "안녕하세요! 다시 만나서 반가워요. 어떻게 도와드릴까요?\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "안녕하세요! 다시 만나서 반가워요. 어떻게 도와드릴까요?\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"next\":\"FINISH\"}"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph, stream_graph\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": 123})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"안녕?\"\n",
    "        ),\n",
    "        \n",
    "    ],\"config\": config\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99fe9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.runnables import RunnableConfig\n",
    "# from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "# # config 설정(재귀 최대 횟수, thread_id)\n",
    "# config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# # 질문 입력\n",
    "# inputs = {\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(\n",
    "#             content=\"2010년 ~ 2024년까지의 대한민국의 1인당 GDP 추이를 그래프로 시각화 해주세요.\"\n",
    "#         ),\n",
    "        \n",
    "#     ],\"config\": config\n",
    "# }\n",
    "\n",
    "# # 그래프 실행\n",
    "# invoke_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25951a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "Retriever\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mRetriever\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retriever (call_RTupIlWikN0XlkoU4YHSZRD8)\n",
      " Call ID: call_RTupIlWikN0XlkoU4YHSZRD8\n",
      "  Args:\n",
      "    query: Midjourney new version\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m in [\u001b[1;33mRetriever\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retriever\n",
      "\n",
      "<document><content>| 12월 | 3~5일   | (소프트웨이브 2025)10회대한민국소프트웨어대전                                     | 서울, 강남                | www.k-softwave.com                                       |\n",
      "| 12월 | 10~11일 | AI Summit New York                                                                | 미국, 뉴욕                | newyork.theaisummit.com                                  |</content><metadata><source>docling_outputs\\SPRi AI Brief_8월호_산업동향_F.md</source><page></page></metadata></document>\n",
      "\n",
      "<document><content>- n AI 이미지 생성 플랫폼 미드저니(Midjourney)가 2025년 6월 19일 비디오 생성 모델 'V1'을 출시\n",
      "- V1은 이미지를 동영상으로 변환하는 모델로, 미드저니 플랫폼에서 제작된 이미지나 외부 이미지를 바탕으로 동영상을 생성하며, '자동' 설정 시에는 모션 프롬프트가 자동으로 생성되고 '수동' 설정을 선택하면 사용자 지시에 따라 사물이나 장면의 움직임을 생성\n",
      "- 사용자는 움직임 강도를 피사체와 카메라가 모두 움직이는 '하이 모션(High Motion)'과 카메라는 거의 고정되어 있고 피사체가 천천히 움직이도록 연출 '로우 모션(Low Motion)' 중에서 선택 가능\n",
      "- 웹 전용 모델인 V1은 1회 동영상 생성 작업으로 5초 길이의 동영상 4개를 제작하며, 생성된 동영상은 한 번에 4초씩 최대 4회까지 영상 길이를 확장할 수 있도록 허용</content><metadata><source>docling_outputs\\SPRi AI Brief_8월호_산업동향_F.md</source><page></page></metadata></document>\n",
      "\n",
      "<document><content><!-- image -->\n",
      "\n",
      "## 기업 ･ 산업\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## 미드저니, 첫 번째 비디오 생성 AI 모델 'V1' 출시\n",
      "\n",
      "## KEY Contents\n",
      "\n",
      "- n 미드저니가 1회 작업으로 5초 길이의 동영상 4개를 제작할 수 있는 비디오 생성 모델 'V1'을 출시하고 여타 비디오 생성 모델보다 25배 이상 저렴한 가격을 책정했다고 강조\n",
      "- n 미드저니는 실시간 오픈월드 시뮬레이션이 가능한 AI 모델 개발을 궁극적 목표로 제시하고, 2026년에 3D 모델과 실시간 처리 모델을 출시한 뒤 각 모델을 하나로 통합할 계획이라고 설명\n",
      "\n",
      "## £ 'V1', 미드저니에서 생성한 이미지나 외부 이미지를 동영상으로 변환</content><metadata><source>docling_outputs\\SPRi AI Brief_8월호_산업동향_F.md</source><page></page></metadata></document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mRetriever\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "미드저니 신버전 관련 최신 정보는 다음과 같습니다:\n",
      "\n",
      "- 미드저니가 2025년 6월 19일에 비디오 생성 모델 'V1'을 출시했습니다.\n",
      "- 'V1'은 이미지를 동영상으로 변환하는 모델로, 미드저니 플랫폼에서 제작된 이미지나 외부 이미지를 바탕으로 동영상을 생성합니다.\n",
      "- 자동 설정 시 모션 프롬프트가 자동 생성되고, 수동 설정 시 사용자가 사물이나 장면의 움직임을 직접 지시할 수 있습니다.\n",
      "- 사용자는 '하이 모션(High Motion)'과 '로우 모션(Low Motion)' 중에서 움직임 강도를 선택할 수 있습니다.\n",
      "- 웹 전용 모델인 V1은 1회 작업으로 5초 길이의 동영상 4개를 제작하며, 생성된 동영상은 최대 4회까지 4초씩 연장할 수 있습니다.\n",
      "- 미드저니는 이 모델을 여타 비디오 생성 모델보다 25배 이상 저렴한 가격에 제공하고 있습니다.\n",
      "- 궁극적으로 2026년에 3D 모델과 실시간 처리 모델을 출시하고, 이를 하나로 통합하는 실시간 오픈월드 시뮬레이션 AI 모델 개발을 목표로 하고 있습니다.\n",
      "\n",
      "출처: SPRI AI Brief 8월호 산업동향 (2025)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mRetriever\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: retriever\n",
      "\n",
      "미드저니 신버전 관련 최신 정보는 다음과 같습니다:\n",
      "\n",
      "- 미드저니가 2025년 6월 19일에 비디오 생성 모델 'V1'을 출시했습니다.\n",
      "- 'V1'은 이미지를 동영상으로 변환하는 모델로, 미드저니 플랫폼에서 제작된 이미지나 외부 이미지를 바탕으로 동영상을 생성합니다.\n",
      "- 자동 설정 시 모션 프롬프트가 자동 생성되고, 수동 설정 시 사용자가 사물이나 장면의 움직임을 직접 지시할 수 있습니다.\n",
      "- 사용자는 '하이 모션(High Motion)'과 '로우 모션(Low Motion)' 중에서 움직임 강도를 선택할 수 있습니다.\n",
      "- 웹 전용 모델인 V1은 1회 작업으로 5초 길이의 동영상 4개를 제작하며, 생성된 동영상은 최대 4회까지 4초씩 연장할 수 있습니다.\n",
      "- 미드저니는 이 모델을 여타 비디오 생성 모델보다 25배 이상 저렴한 가격에 제공하고 있습니다.\n",
      "- 궁극적으로 2026년에 3D 모델과 실시간 처리 모델을 출시하고, 이를 하나로 통합하는 실시간 오픈월드 시뮬레이션 AI 모델 개발을 목표로 하고 있습니다.\n",
      "\n",
      "출처: SPRI AI Brief 8월호 산업동향 (2025)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "FINISH\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 수정된 코드 테스트\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": 123})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"미드저니 신버전은? SPRI에서 찾아줘\"\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(graph, inputs, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed566b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "General LLM\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mGeneral LLM\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "이전 질문은 \"미드저니 신버전은? SPRI에서 찾아줘\"였습니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: general\n",
      "\n",
      "이전 질문은 \"미드저니 신버전은? SPRI에서 찾아줘\"였습니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "FINISH\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 수정된 코드 테스트\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": 123})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"이전 나의 질문은?\"\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(graph, inputs, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06e05ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "FINISH\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 수정된 코드 테스트\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph, stream_graph\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": 123})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"미드저니 신버전\"\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(graph, inputs, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b27632b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"next\":\"FINISH\"}"
     ]
    }
   ],
   "source": [
    "# 수정된 코드 테스트\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph, stream_graph\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": 123})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"안녕??\"\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(graph, inputs, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8780d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a40cc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 실제 챗봇 환경 시뮬레이션 ===\n",
      "같은 질문이 여러 번 들어와도 매번 답변해야 합니다.\n",
      "\n",
      "1️⃣ 첫 번째 질문:\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "General LLM\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mGeneral LLM\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕! 어떻게 도와줄까?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: general\n",
      "\n",
      "안녕! 어떻게 도와줄까?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "General LLM\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mGeneral LLM\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕! 무엇을 도와줄까? 궁금한 점이나 필요한 게 있으면 말해줘!\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: general\n",
      "\n",
      "안녕! 무엇을 도와줄까? 궁금한 점이나 필요한 게 있으면 말해줘!\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "General LLM\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mGeneral LLM\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕! 만나서 반가워. 오늘 어떻게 도와줄까?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: general\n",
      "\n",
      "안녕! 만나서 반가워. 오늘 어떻게 도와줄까?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "General LLM\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mGeneral LLM\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요! 만나서 반가워요. 무엇을 도와드릴까요?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: general\n",
      "\n",
      "안녕하세요! 만나서 반가워요. 무엇을 도와드릴까요?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mSupervisor\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mnext\u001b[0m:\n",
      "General LLM\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m in [\u001b[1;33mGeneral LLM\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요! 무엇을 도와드릴까요? 궁금한 점이나 필요한 정보가 있으면 말씀해 주세요.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mGeneral LLM\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: general\n",
      "\n",
      "안녕하세요! 무엇을 도와드릴까요? 궁금한 점이나 필요한 정보가 있으면 말씀해 주세요.\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     10\u001b[39m config1 = RunnableConfig(recursion_limit=\u001b[32m10\u001b[39m, configurable={\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: random_uuid()})\n\u001b[32m     11\u001b[39m inputs1 = {\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     13\u001b[39m         HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33m안녕?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     ]\n\u001b[32m     15\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result1 = \u001b[43minvoke_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 두 번째 질문 (같은 내용)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\skyop\\jaeho_template\\dotenv\\Lib\\site-packages\\langchain_teddynote\\messages.py:409\u001b[39m, in \u001b[36minvoke_graph\u001b[39m\u001b[34m(graph, inputs, config, node_names, callback)\u001b[39m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m namespace[-\u001b[32m1\u001b[39m].split(\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(namespace) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mroot graph\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# subgraphs=True 를 통해 서브그래프의 출력도 포함\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    411\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# node_names가 비어있지 않은 경우에만 필터링\u001b[39;49;00m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_names\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\skyop\\jaeho_template\\dotenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2343\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2335\u001b[39m     msg = create_error_message(\n\u001b[32m   2336\u001b[39m         message=(\n\u001b[32m   2337\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2341\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2342\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2344\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2345\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# 실제 챗봇 환경 시뮬레이션 - 같은 질문 반복 테스트\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "print(\"=== 실제 챗봇 환경 시뮬레이션 ===\")\n",
    "print(\"같은 질문이 여러 번 들어와도 매번 답변해야 합니다.\")\n",
    "\n",
    "# 첫 번째 질문\n",
    "print(\"\\n1️⃣ 첫 번째 질문:\")\n",
    "config1 = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "inputs1 = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕?\")\n",
    "    ]\n",
    "}\n",
    "result1 = invoke_graph(graph, inputs1, config1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 두 번째 질문 (같은 내용)\n",
    "print(\"\\n2️⃣ 두 번째 질문 (같은 내용):\")\n",
    "config2 = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "inputs2 = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕?\")\n",
    "    ]\n",
    "}\n",
    "result2 = invoke_graph(graph, inputs2, config2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 세 번째 질문 (같은 내용)\n",
    "print(\"\\n3️⃣ 세 번째 질문 (같은 내용):\")\n",
    "config3 = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "inputs3 = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕?\")\n",
    "    ]\n",
    "}\n",
    "result3 = invoke_graph(graph, inputs3, config3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 없는 그래프로 테스트 (각 질문이 완전히 독립적)\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 메모리 없는 그래프 생성\n",
    "workflow_no_memory = StateGraph(AgentState)\n",
    "\n",
    "# 그래프에 노드 추가\n",
    "workflow_no_memory.add_node(\"Retriever\", retriever_node)\n",
    "workflow_no_memory.add_node(\"Researcher\", research_node)\n",
    "workflow_no_memory.add_node(\"Coder\", coder_node)\n",
    "workflow_no_memory.add_node(\"General LLM\", general_node)\n",
    "workflow_no_memory.add_node(\"Supervisor\", supervisor_agent)\n",
    "\n",
    "# 멤버 노드 > Supervisor 노드로 엣지 추가\n",
    "for member in members:\n",
    "    workflow_no_memory.add_edge(member, \"Supervisor\")\n",
    "\n",
    "# 조건부 엣지 추가\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "\n",
    "def get_next(state):\n",
    "    return state[\"next\"]\n",
    "\n",
    "# Supervisor 노드에서 조건부 엣지 추가\n",
    "workflow_no_memory.add_conditional_edges(\"Supervisor\", get_next, conditional_map)\n",
    "\n",
    "# 시작점\n",
    "workflow_no_memory.add_edge(START, \"Supervisor\")\n",
    "\n",
    "# 메모리 없는 그래프 컴파일 (수정된 general_node 반영)\n",
    "graph_no_memory = workflow_no_memory.compile()  # checkpointer 없음\n",
    "\n",
    "print(\"=== 메모리 없는 그래프 재생성 완료 ===\")\n",
    "print(\"이제 각 질문이 완전히 독립적으로 처리됩니다.\")\n",
    "print(\"general_node도 react_agent를 사용하여 무한루프를 방지합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba294dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 없는 그래프로 같은 질문 반복 테스트\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "print(\"=== 메모리 없는 그래프로 같은 질문 반복 테스트 ===\")\n",
    "\n",
    "# 첫 번째 질문\n",
    "print(\"\\n1️⃣ 첫 번째 질문:\")\n",
    "inputs1 = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕?\")\n",
    "    ]\n",
    "}\n",
    "result1 = invoke_graph(graph_no_memory, inputs1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 두 번째 질문 (같은 내용)\n",
    "print(\"\\n2️⃣ 두 번째 질문 (같은 내용):\")\n",
    "inputs2 = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕?\")\n",
    "    ]\n",
    "}\n",
    "result2 = invoke_graph(graph_no_memory, inputs2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 세 번째 질문 (같은 내용)\n",
    "print(\"\\n3️⃣ 세 번째 질문 (같은 내용):\")\n",
    "inputs3 = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕?\")\n",
    "    ]\n",
    "}\n",
    "result3 = invoke_graph(graph_no_memory, inputs3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정된 general_node 테스트 (무한루프 방지)\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "print(\"=== 수정된 general_node 테스트 ===\")\n",
    "print(\"이제 general_node도 react_agent를 사용하여 무한루프를 방지합니다.\")\n",
    "\n",
    "# 새로운 thread_id로 config 설정\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"안녕?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 수정된 그래프로 실행\n",
    "result = invoke_graph(graph, inputs, config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
