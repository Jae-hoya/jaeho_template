{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74772c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa831a9",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25666ba6",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c467af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFPlumberLoader, TextLoader\n",
    "\n",
    "import glob\n",
    "\n",
    "# data 폴더 안의 모든 PDF 가져오기\n",
    "docs = glob.glob(\"docling_outputs/*.md\")\n",
    "\n",
    "# docs = [\"data/LangGraph-Based Integrated Architecture for CrewAI Multi-Agent.pdf\",\n",
    "#        \"data/insight_Agentic.pdf\"]\n",
    "\n",
    "all_docs = []\n",
    "for d in docs:\n",
    "    loader = TextLoader(d, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "    all_docs.extend(docs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b2c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'docling_outputs\\\\insight_Agentic.pdf.md'}, page_content='## Document 1\\n\\nJournal of the Korea Institute of Information and Communication Engineering\\n\\n한국정보통신학회논문지 Vol. 23, No. 1: 399~406, Mar. 2019\\n\\n## Agentic RAG 시스템 구현 경험에 기반한 설계 인사이트\\n\\n김재호 1 · 김장영 2*\\n\\n## Design Insights from Empirical Experiences in Implementing Agentic RAG Systems\\n\\n## Jae-Ho Kim 1 · Jang-Young Kim 2*\\n\\n1 Graduate Student, Department of Computer Science, The University of Suwon, Hwaseong, 18323 Korea 2 * Associate Professor, Department of Computer Science, The University of Suwon, Hwaseong, 18323 Korea\\n\\n## 요 약\\n\\nRetrieval-Augmented Generation(RAG)과 Fine-tuning 기반 Slim Language Model(SLM)의 구조적 차이 와장단점,그리고AgenticRAG 시스템 설계시고려해야 할핵심요소를분석하였다.텍스트분할방법,임베딩 모델선정, LLM 및 에이전트 워크플로우의 아키텍처 선택이 전체 시스템 성능, 검색 정확도, 안정성에 미치는 영향을살펴보았다. 또한, 무한루프, 분기 조건의 모호성, 도구 선택의 불일치 등 실제로 발생할 수 있는 문제점 과그해결방안도제시하였다.연구결과,자동오류감지및회복로직의구현,도메인특화워크플로우최적화, LLM과 임베딩 모델의 정량적 평가가 중요함을 확인하였다. 더불어 실시간 사용자 피드백 반영이 시스템의적 응성과동적관리에효과적임을제안한다.이러한방향들은RAG및AgenticRAG 시스템의신뢰성,확장성,실 제적용가능성향상에중요한연구과제가될것이다.\\n\\n## ABSTRACT\\n\\nThe structural differences, strengths, and limitations of Retrieval-Augmented Generation (RAG) compared to fine-tuned Slim Language Models (SLMs) are examined, focusing on key considerations for designing Agentic RAG systems. The analysis explores how choices in text chunking methods, embedding model selection, and the architecture of LLMs and agentic workflows impact overall system performance, retrieval precision, and operational stability. Challenges such as infinite loops, ambiguous branching, and inconsistent tool selection are discussed, along with potential strategies for mitigation. The findings highlight the importance of implementing automatic error detection and recovery, optimizing domain-specific workflows, and quantitatively evaluating both LLMs and embedding models. Moreover, incorporating real-time user feedback is identified as an effective approach for improving adaptability and dynamic workflow management. These directions are suggested as important focal points for future research and development, aiming to enhance the reliability, scalability, and practical applicability of RAG and Agentic RAG frameworks in advanced AI applications.\\n\\n키워드 : 임베딩, 대형 언어 모델, 검색 증강 생성(RAG), 에이전틱 RAG\\n\\nAssociate Professor,\\n\\nOpen Access http://doi.org/10.6109/jkiice.2019.23.1.399\\n\\npISSN:2234-4772\\n\\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License(http://creativecommons.org/li \\xadcenses/ by-nc/3.0/) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.\\n\\nCopyright The Korea Institute of Information and Communication Engineering.\\n\\nKeywords : Embedding, LLM(Large Language Model), RAG(Retrieval Augmented Generation), Agentic RAG\\n\\n## Ⅰ. 서 론\\n\\n최근 LLM(대형 언어 모델) 분야에서 가장 주목받는 기술로는 RAG(Retrieval-Augmented Generation)와 fine-tuning을 통한 SLM(Slim Language Model)이 꼽힌다. 최근 여러 컨퍼런스 동향을 보면, RAG와 SLM(fine-tuning)이며, 강연 중 절반 이상은 SLM 및 fine-tuning, 모델 아키텍처 관련 논의가 집중적으로 이루어지고 있다.\\n\\n그러나 최근 MCP 및 AI Agent 기술이 빠르게 발 전함에 따라, 실제 현업 및 서비스 환경에서는 RAG의 중요성이 다시금 부각되고 있다고 필자는 판단한다. 본 논문은 이러한 최신 기술 동향을 고려할 때, 기존 fine-tuning 중심의 접근법만으로는 한계가 존재하며, RAG가 향후 LLM 기반 AI 시스템에서 더욱 전략적이 고 핵심적인 역할을 할 것으로 기대한다[1]. 이에 본 연구에서는 RAG를 중심으로 한 경험적 분석과 실제 적용 사례를 제시하고, AI Agent 환경에서의 RAG 설 계및운용상의인사이트를제공하고자한다.\\n\\n본 논문에서는 RAG 시스템을 구현하면서 경험한 다양한 사례를 바탕으로, RAG 구조와 Agentic 환경 에서의 LLM 및 Embedding 모델 선택이 시스템 성능 에 미치는 영향, 텍스트 분할 및 노드 구조에 따른 출 력 방식과 무한루프 발생 가능성등을 고찰한다.이를 통해 기존 연구에서 다루지 않은 실제적인 RAG 설계 및운용인사이트를제시하고자한다.\\n\\n## 1.1 Fine-Tuning과 RAG\\n\\nFine-tuning은 특정 작업이나 도메인에 맞춰 LLM 의 파라미터를 재학습시켜, 해당 지식을 모델 내부에 내재화하는 방식이다. 이는 특정 도메인 지식에 특화 된 경량 모델 구현, 프롬프트 단순화 등의 이점을 제 공하나, 대규모 연산 자원, 고품질 데이터, 장시간의 학습이 필요하며 오버피팅, 데이터 편향, 파라미터 충 돌등의문제가발생할수있다[2].\\n\\n반면, RAG는 외부 문서 기반 검색을 통해 LLM이 내재하지 않은 지식을 실시간으로 보완하는 구조이다. RAG는 실시간성, 도메인 유연성, 최신 정보 반영 등 에서 강점을 가지며, 데이터 품질 부담이 상대적으로 낮고, 할루시네이션 현상 완화 및 재학습 불필요성 등 의장점이있다. 단, 검색 및 임베딩 성능에 따라 답변\\n\\n의 품질이 좌우되며, 복잡한 질문이나 맥락에서는 성 능저하가발생할수있다[3].\\n\\nAI 에이전트 기반 modular RAG가 등장하여, 다양 한 도구 및 메모리, 사전 지식을 바탕으로 복합적인 검색 및 추론을 수행하는 구조가 제안되고 있다. 이러 한 구조에서는 각 에이전트가 도메인별 데이터 검색 및 답변 생성을 담당하며, fine-tuning이 제공하는 지 식내재화효과를일정부분대체할수있음을시사한 다[4].\\n\\nFig. 1 Workflow Comparison of Fine-Tuning and RAG\\n\\n위그림1은, Fine-tining과 RAG의 흐름을 표로 간 략히비교하는이미지다.\\n\\n## Ⅱ. 배경 및 기존연구\\n\\n최근 LLM 기반 생성형 AI 분야에서는, 외부 지식 의 효과적인 활용을 위해 RAG와 fine-tuning을 통한 SLM이 주요 연구 주제로 부각되고 있다. 특히 RAG 는 LLM의 한계로 지적되는 최신성, 도메인 특화, 할 루시네이션 완화 등에 효과적이라는 점에서 다양한 실무 및 연구 환경에서 빠르게 도입되고 있다. Lewis et al. (2020)은 외부 문서로부터 정보를 검색하고, 이를 기반으로 LLM이 응답을 생성하는 RAG 구조를 최초로 제안하였다[3]. 이 방식은 LLM의 내재 지식 한계와 데이터 최신성 문제를 효과적으로 보완한다. 그러나 기존 RAG는 주로 정적 파이프라인 구조로\\n\\n설계되어, 복잡한 멀티스텝 추론, 동적 분기, 도구 호 출 등에서는 유연성이 떨어진다는 한계가 지적된다. 이러한 한계를 극복하기 위해, reflection, planning, tool-use, multi-agent collaboration 등 에이전트 기 반의 패턴을 도입한 Agentic RAG 개념이 대두되고 있다. 기존 RAG의 단점을 보완하고, 다양한 워크플 로우 설계 및 도구 활용이 가능한 Agentic RAG의 개념과 발전 방향을 체계적으로 정리하였다. 이 연 구에서는 Single Agent Router, Multi Agent System, Hierarchical/ Graph-Based 등 다양한 Agentic RAG 구조와 실제 적용 사례, 운영상의 도전과제까지 종 합적으로 다루고 있다[4].\\n\\n본 연구는 기존 RAG와 Agentic RAG의 주요 연구 흐름을 바탕으로, RAG 시스템 설계, 에이전트/워크 플로우 도입, 그리고 실제 적용 과정에서 확인된 개 선 방향에 대해 고찰한다.\\n\\n## Ⅲ. 운영 경험과 주요 쟁점\\n\\n## 4.1 Text\\\\_splitter 및 Embedding 모델\\n\\nRAG 시스템에서 대표적으로 사용하는 텍스트 분 할 방법에는 Recursive Character Text Splitter와 Semantic Chunker가 있다[5]. Recursive Character Text Splitter는 일정 길이로 텍스트를 단순하게 나누 는 방식이고, Semantic Chunker는 문서의 의미적 경 계를 기준으로 분할하는 방식이다.\\n\\n임베딩 모델은, Vector DB에 저장할 벡터를 생성 하거나, Semantic Chunker에서 의미 단위 분할 시에 사용된다. 임베딩 모델은 벡터 차원, 도메인 적합도 등에 따라 성능이 달라지며, BGE-M3와 OpenAI 모 델이 대표적이다.\\n\\nEmbedding Model Performance Comparison\\n\\nFig. 2 Comparison of Embedding Model and Text\\n\\n## Splitter Performance\\n\\n위 그림2 에서는, 검색 성능을 비교를 보여준다. 실제 프로젝트에서 사용했던 3종의 영문 서적 텍스 트(사주, 타로)를 활용하였다. 이 데이터들을 일반적 으로 좋은 성능을 가지는, RecursiveCharacter TextSplitter (chunk\\\\_size=1000, chunk\\\\_overlap=200) 로 분할하였고[6], Semantic Chinker의 엠베딩은 BGE-M3, text embedding 3 small 모델을 사용하였 다. 벡터 데이테 베이스 임베딩에 있어서는, BGE-M3 와 text embedding 3 small 임베딩 모델을 각각 적 용하여, 각 설정이 RAG의 검색 정확도와 인덱싱 효 율에 미치는 차이를 경험적으로 관찰할 수 있었다. 임베딩 모델은 학습 데이터의 도메인에 따라 실제 검색 정확도 및 표현력에서 차이가 발생할 수 있다.\\n\\n## 4.2 LLM 선택에 따른 경험\\n\\nLLM은 Open Source LLM(Llama, Deepseek, Gemma 등)과 Closed Source LLM(ChatGPT, Claude, Gemini 등)으로 구분될 수 있다. 많은 사용자들은 비용 및 보안성 때문에 OpenSource LLM을 많이 선 호하지만, 고성능 GPU와 속도 한계등 현실적인 제 약으로 인해, 실제 서비스나 실험에서는 API기반인 Closed LLM을 많이 사용하게 되는 경우가 발생한 다.. 특히 AI Agent에 있어서, Closed LLM은 fine-tuning된 Instuction model이 필요한데 낮은 Intelligence 수준이 낮은 경우 성능 저하가 뚜렷하게 나타났다[7].\\n\\n본 연구에서는 대표적 Closed LLM인 GPT 계열 모델을 대상으로, 프로젝트 환경에서 retriever(문서 검색), prompt 이해, Agentic RAG(에이전트적 워크 플로우) 수행 능력을 비교하였다.\\n\\nTable1. Comparative Performance of Different GPT Models\\n\\n| Model         | Retriever   | Prompt Understanding   | Agentic RAG Capabality   |\\n|---------------|-------------|------------------------|--------------------------|\\n| gpt-4o- mini  | Fair        | Fair                   | Poor                     |\\n| gpt-4o        | Excellent   | Excellent              | Excellent                |\\n| gpt-4.1- mini | Excellent   | Excellent              | Excellent                |\\n| gpt-4.1- nano | Poor        | Poor                   | Poor                     |\\n\\n위 표 1는 gpt모델별 수행력 평가이다. 실험 결과\\n\\ngpt-4o-mini는 프롬프트 해석에 다소 한계가 있었고, retriever에서도 일부 제약이 있었다. 반면, gpt-4o와 gpt-4.1-mini는 retriever, prompt 해석, agentic RAG 모두에서 우수한 성능을 보였다. gpt-4.1-nano는 prompt 이해와 agentic rag 수행 모두에서 성능이 미흡했으며,retriever 자체도 정확하게 동작하지 못했 다.\\n\\n## 4.3 AI Agent에서의 경험\\n\\n최근 대형 언어모델(LLM)의 발전과 더불어, 복 잡한 작업을 자동화할 수 있는 AI Agent 시스템 의 필요성이 크게 부각되고 있다. 특히, 문서 기 반 답변에서 RAG가 등장하면서, 단순한 답변 생 성에서 벗어나 문맥 파악, 동적 추론, 그리고 다 양한 도구 호출 등 복합적인 워크플로우를 스스 로 설계하고 실행할 수 있는 Agentic RAG 구조 가 주목받고 있다. 이러한 시스템은 사용자의 질 문 의도와 문맥을 파악한 뒤, 필요한 도구를 선 택해 호출하거나, 복수의 에이전트가 협력하여 문제를 해결하는 Multi-Agent System으로 확장 될 수 있다는 점에서 기존 RAG와 구별된다. 본 논문에서는 이처럼 동적인 워크플로우 설계, 문 맥 기반 의사결정, 자동 도구 활용이 가능해진 Agentic RAG 구현 경험과, 실제 운용 과정에서 얻은 실무적 인사이트를 중심으로 각 툴과 시스 템의 특징을 분석하였다.\\n\\nAI Agent 기반 RAG 시스템의 설계에서는 많은 개발자와 연구자들이 다양한 선택지 앞에서 고민하 게 된다. 특히, Single Agent System과 Multi Agent System 중 어떤 구조를 채택할지, 그리고 에이전트 와 툴을 연결하는 올바른 구현 방식에 대한 고민이 깊다. Agent와 tool을 연결하는 방식에서, LangChain 과 LangGraph를 활용하는 실제 개발 환경은 다음과 같다.\\n\\n첫째, 여러 툴을 리스트로 묶어 llm.bind\\\\_tools를 통해 LLM에 직접 바인딩하는 방식이 있다. 이 방법 은 코드가 간결하고, 다양한 툴을 손쉽게 실험적으 로 추가하거나 제거할 수 있다는 장점이 있다. 그러 나 이 방식은 각 툴의 역할과 사용법에 대한 명확한 설명이 LLM에 충분히 제공되지 않는 경우가 많아, LLM의 툴 선택 로직이 일관되지 않고 불안정해지는\\n\\n문제가 자주 발생한다. 특히, 대규모 시스템이나 멀 티툴 환경에서 llm.bind\\\\_tools 방식만 사용할 경우 각 툴의 고유 기능이나 목적이 프롬프트에서 충분히 분리·강조되지 않으므로 LLM이 상황에 따라 잘못된 툴을 선택하거나, 동일한 입력에 대해 서로 다른 툴 을 사용하는 등 답변 결과의 일관성이 크게 떨어지 는 현상이 나타날 수 있다. 따라서, 소규모 실험이나 빠른 프로토타이핑에는 llm.bind\\\\_tools가 편리\\n\\n둘째, 각 툴을 @tool 데코레이터를 사용해 명확한 설명과 함께 선언한 후, 이를 create react agent와 같이 에이전트 생성 시 명시적으로 등록하는 방식이 다. 이 방법은 각 툴의 역할과 입력/출력에 대한 설 명이 LLM에 명확히 전달되므로, 툴 선택의 일관성과 신뢰성을 높일 수 있다는 장점이 있다. 특히 대규모 시스템이나 복잡한 멀티에이전트 환경에서 효과적이 다. 또한, create retriever tool을 활용해 RAG 특화 에이전트 생성 함수가 도입하여, 검색기와 생성기를 결합하거나 분리하는 다양한 워크플로우 설계가 가 능해졌다. 이러한 방식은 RAG 시스템의 특성에 맞게 최적화된 에이전트 구성이 가능하도록 해준다.\\n\\nAI Agent 시스템의 설계와 구현 방식은 프로젝트 목적, 시스템 복잡도, 그리고 툴 설명 및 역할 분배 의 명확성에 따라 신중히 선택해야 한다. 각 방식의 장단점과 한계를 충분히 고려하는 것이 필수적이다.\\n\\nTable2. Comparison of Key Agentic Functions/Patterns in LangChain &amp; LangGraph\\n\\n위 표2에서, LangChain 및 LangGraph 기반의 agentic RAG 시스템을 설계할 때, 대표적으로 세 가 지 주요 방식을 고려할 수 있다.\\n\\n| Aspect        | Create React agent            | Create Retrievr tool                | Llm bind_tools                      |\\n|---------------|-------------------------------|-------------------------------------|-------------------------------------|\\n| Role/ Purpose | Create Agent                  | Add Retriever Tool                  | Bind LLM with Tools                 |\\n| Scope/ Level  | Agent Level                   | Tool Level                          | LLM Level                           |\\n| Strength      | Scalability, Integration      | Easy to Add Retrieval Tool          | Simplicity                          |\\n| Ceveat        | Complex Setup, Initialization | Requires Create React agent for Use | Not suitable for large scale system |\\n\\n첫째, llm.bind\\\\_tools는 LLM에 다양한 도구를 직접 바인딩하여, LLM 자체가 마치 에이전트처럼 도구를 호출할 수 있도록 하는 방식이다. 빠른 실험 및 함 수 호출 테스트, 코드 간결성 등에서 유리하나, description 정보가 LLM에 직접적으로 충분히 전달 되지 않으면 일관성 있는 행동이 어렵고, 대규모 시 스템에는 부적합할 수 있다. LLM자체가 Tool call agent처럼 행동하게 하는 설정이다.\\n\\n둘째, create\\\\_retriever\\\\_tool은 검색기를 agent가 사 용할 수 있는 개별 도구로 래핑하는 역할을 한다. 이 방식은 RAG 시스템 내에서 검색 기능을 손쉽게 agent에 추가할 수 있다는 이점이 있다. 그러나 툴 생성 시 반드시 명확한 설명이 포함되어야 하며, 해 당 tool은 단독으로 사용되지 않고 반드시 create react agent 등과 결합하여 운용되어야 한다. agent 가 쓸수 있는 도구로 변환해주는 역할이다.\\n\\n셋째, create react agent는 LLM과 다양한 도구를 결합하여 통합 에이전트를 생성하는 방식이다. 이 구조는 복수의 도구를 유기적으로 활용할 수 있고, 시스템의 확장성이 뛰어나다는 장점이 있다. 다만, 초기 설정이 복잡하고 전체 구조의 난이도가 높아질 수 있으므로, 설계 단계에서 신중한 구성이 필요하 다. 즉 하나의 Agent가 만들어진다.\\n\\n이처럼, 각 방식은 Agentic RAG/워크플로우에서 사용될 수 있으며, 적용 위치, 장단점, 그리고 설계상 주의할 점이 상이하므로, 시스템의 규모와 목적에 따라 적합한 방법을 선택하는 것이 바람직하다.\\n\\n여기서, create react agent를 LangGraph의 노드 로 만들어서 실행하였을때, tool에서 틀렸던 코드를 수정하여 실행시켜 줬던점이다. 일반 llm을 명시하는 코드에서 moㅇel로 오타를 냈는데, 알아서 model로 바꿔서 코드를 실행시켜주는 경험이 있었다. agent 로 만들어 주는 순간, LLM이 작성한 코드에도 관여 를 한다는 것이 발견하였고, 이것은 앞으로 강력한 무기가 될것으로 예상된다.\\n\\n## Ⅳ . LangGraph 기반 RAG 구조 설계\\n\\nLangGraph를 활용한 RAG 시스템에서는 route trigger, query expansion, query rewrite, 바리게이트 노드 등 다양한 워크플로우 모듈이 적극적으로 사용\\n\\n된다[8]. 각 모듈은 질의 처리와 답변 정확도 향상에 기여하지만, 분기 조건이 명확하지 않거나 상태 관 리가 미흡하면 무한루프와 같은 예기치 못한 오류가 자주 발생한다. 쉽게 예시를 들자면, query expansion이나 query rewrite 노드에서, 사용자의 질 문을 받아, 더 나은 질문으로 바꿔달라고 하는 경우, 사용자의 의도와 다르게 변환되는 경우, 변환 경우 에도 올바르게 답변하지 못해 조건분기가 동작하지 않아 동일한 루트를 순환하며 무한루프에 빠질 수 있다. 바리게이트 노드에서 이후 경로로의 진행을 차단하도록 설계할 수 있는데, 이 차단 이후 사용자 의 입력을 반복적으로 \\'질문 재작성(query rewrite)\\' 노드로 되돌려 보내거나, 바리게이트 노드 자체로 재진입하도록 설정할 경우, 입력 수정이 없을 때 워 크플로우가 \\'바리게이트 ↔ 질문 재작성\\' 사이를 계 속 순환하며 무한루프에 빠지게 되는 현상이 발생할 수 있다. 실제로, 사용자가 잘못된 입력을 계속 수정 하지 않을 때 워크플로우는 종료되지 않고, 동일한 노드를 무한 반복하게 된다.\\n\\n또 다른 사례로, 워크플로우에서 여러 외부 API 호출 노드(예: 검색 도구, 문서 요약 도구, 번역 도구 등)가 연속적으로 배치되어 있는 경우, 각 노드의 실 패/재시도 로직이 명확하게 제한되지 않으면 하나의 API 호출이 실패할 때마다 재시도를 무제한으로 반 복하게 되어 전체 워크플로우가 종료되지 않고 무한 루프에 빠질 수 있다. API 호출 실패 시 \\'다시 시도\\' 로직이 횟수 제한 없이 항상 트리거되도록 설정되어 있으면, 일정 시간 동안 동일한 API 요청이 계속 반 복되어 결국 API 호출 한도 초과 또는 시스템 과부 하가 발생하는 문제가 생긴다. 예를 들어, 이러한 문 제를 예방하기 위해서는 각 노드의 분기 조건과 상 태 관리, 재시도 한계 및 탈출 조건을 명확히 설계 하는 것이 필수적이다.\\n\\n## Ⅴ. 결론 및 향후연구\\n\\n본 논문에서는 Fine-tuning 기반 SLM과 RAG 의 구조적 차이와 장단점을 비교 분석하고, RAG 와 Agentic RAG 시스템 설계 시 고려해야 할 주요 이슈들을 실험적으로 제시하였다. \"다양한 실험과 분석을 통해 텍스트 분할 방식, 임베딩\\n\\n모델 선택, LLM 유형 및 Agentic 설계 방식 등 이 RAG 시스템의 전반적인 성능에 직접적인 영 향을 미치며, 실제 운용 과정에서 무한루프, 분 기 조건 관리 미흡, 도구 선택의 불일치와 같은 현실적 문제점이 나타남을 확인하였다. 특히 LangGraph 와 같은 워크플로우 기반 프레임워크 를 활용할 때, 각 노드의 상태 관리와 재시도 조 건, 도구의 역할 정의 등 세부 설계가 시스템의 안정성과 효율성에 매우 중요하다는 점이 부각 되었다. 또한, API 호출 한도 초과, 입력 무한 반 복 등 다양한 장애 가능성에 대응하기 위해서는, 분기 조건의 명확한 정의와 워크플로우의 탈출 조건 설계가 필수적임을 알 수 있었다.\\n\\n향후 연구 및 개발 방향으로는 Agentic RAG 시스템의 자동 오류 감지 및 회복 로직 강화, 도 메인 특화 워크플로우의 최적화, 다양한 LLM 및 임베딩 모델의 정량적 성능 평가, 그리고 실시간 사용자 피드백을 반영한 동적 워크플로우 개선 등이 중요하게 제시된다. 즉, RAG와 Agentic RAG 시스템의 성능은 LLM 모델 선택, 텍스트 분할 기법, 임베딩 전략, 그리고 워크플로우의 명확한 상태 관리 및 분기 조건 설계에 의해 결 정된다. 이러한 후속 연구가 이루어진다면, RAG 및 Agentic RAG 시스템의 안정성과 효율성, 그 리고 실질적인 활용 가능성이 더욱 높아질 것으 로 기대된다.\\n\\n## REFERENCES\\n\\n- [1] H. Soudani, E. Kanoulas, and F. Hasibi, \\'Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge,\\' arXiv preprint arXiv:2403.01432, Mar. 2024. DOI: 10.48550/arXiv.2403.01432.\\n- [2] E. J. Hu, Y. Shen, P. Wallis, Z. Allen -Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, \\'LoRA: Low -Rank Adaptation of Large Language Models,\\' arXiv preprint arXiv:2106.09685, Jun. 2021. DOI: 10.48550/arXiv.2106.09685.\\n- [3] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. Y. Wang, and S. Riedel, \\'Retrieval -Augmented Generation for Knowledge -Intensive NLP Tasks,\\' arXiv preprint arXiv:2005.11401, May 2020. DOI:\\n\\n10.48550/arXiv.2005.11401.\\n\\n- [4] A. Singh, A. Ehtesham, S. Kumar, and T. Talaei Khoei, \\'Agentic Retrieval -Augmented Generation: A Survey on Agentic RAG,\\' arXiv preprint arXiv:2501.09136, Jan. 2025. DOI: 10.48550/arXiv.2501.09136.\\n- [5] R. Qu, R. Tu, and F. Bao, \\'Is Semantic Chunking Worth the Computational Cost?,\\' arXiv preprint arXiv:2410.13070, Oct. 2024. DOI: 10.48550/arXiv.2410.13070.\\n- [6] R. Rao, \\'How to Optimize Chunk Sizes for RAG in Production,\\' Towards AI [Online]. Jun. 2024. A v a i l a b l e : https://pub.towardsai.net/how-to-optimize-chunk-siz es-for-rag-in-production-fae9019796b6\\n- [7] S. Ghosh, C. K. Reddy Evuru, S. Kumar, R. S., D. Aneja, Z. Jin, R. Duraiswami, and D. Manocha, \\'A Closer Look at the Limitations of Instruction Tuning,\\' arXiv preprint arXiv:2402.05119, Feb. 2024. DOI: 10.48550/arXiv.2402.05119.\\n- [8] S. Jeong, J. Baek, S. Cho, S. J. Hwang, and J. Park, \\' Adaptive -RAG: Learning to Adapt Retrieval -Augmented Large Language Models through Question Complexity,\\' arXiv preprint arXiv:2403.14403, Mar. 2024. DOI: 10.48550/arXiv.2403.14403.\\n\\n## 김재호(Jae-Ho Kim)\\n\\n수원대학교컴퓨터학부학사\\n\\n수원대학교컴퓨터학부석사\\n\\n- 수원대학교컴퓨터학부박사과정\\n\\nLangchain Opentutorial Core Contributor ※관심분야: 인공지능, LLM, RAG, AI Agent\\n\\n## 김장영(Jang-Young Kim)\\n\\n연세대학교컴퓨터과학공학사 Pennsylvania State Univ. 공학석사 State University of New York 공학박사 University of South Carolina 교수 수원대학교컴퓨터학부교수 ※관심분야: Big data, AI, Cloud computing, Networks\\n\\n'), Document(metadata={'source': 'docling_outputs\\\\LangGraph-Based Integrated Architecture for CrewAI Multi-Agent.pdf.md'}, page_content=\"## Document 1\\n\\nJournal of the Korea Institute of Information and Communication Engineering\\n\\n한국정보통신학회논문지 Vol. 23, No. 1: 399~406, Mar. 2019\\n\\n## LangGraph 기반 CrewAI 다중 에이전트 통합 아키텍처\\n\\n김재호 1 · 김장영 2*\\n\\n## LangGraph-Based Integrated Architecture for CrewAI Multi-Agent Systems\\n\\n## Jae-Ho Kim 1 · Jang-Young Kim 2*\\n\\n1 Graduate Student, Department of Computer Science, The University of Suwon, Hwaseong, 18323 Korea 2 * Associate Professor, Department of Computer Science, The University of Suwon, Hwaseong, 18323 Korea\\n\\n## 요 약\\n\\n최근 대형 언어 모델(LLM)의 급속한 발전과 함께, 다양한 도메인에서 복잡한 문제를 해결하기 위한 Multi-Agent System(MAS)이 새롭게 주목받고 있다. 본 연구에서는 역할 기반 협업 구조의 CrewAI와 그래프 기 반워크플로우및상태오케스트레이션에강점을지닌LangGraph를통합한하이브리드아키텍처를제안한다. CrewAI는 Agent, Task, Crew 단위의 모듈화로 개발 현장에서의 접근성을 높이지만, 내부 데이터 흐름과 협업 과정은블랙박스화되어복잡한시나리오에서는투명성과디버깅에한계가있다.반면,LangGraph는상태기반 그래프 모델을 통해 전체 워크플로우를 명확하게 시각화하여 확장성과 유지보수성을 크게 향상시킨다. 특히, 본연구는CrewAI의 엔티티를 LangGraph의 노드로 래핑하여, 모듈화된 워크플로우와 유연한 오케스트레이션, 그리고동적도구통합을실현함으로써,고도화된RAG파이프라인과도메인별응용에서우수한성능과확장성 을실험적으로입증하였다.\\n\\n## ABSTRACT\\n\\nWith the rapid advancement of large language model (LLM), Multi-Agent Systems (MAS) have garnered renewed attention as a means of solving complex problems across diverse domains. This paper proposes a hybrid architecture that integrates CrewAI, which features a role-based collaboration structure, with LangGraph, known for its strengths in graph-based workflow and state orchestration. While CrewAI enhances accessibility in development environments through modularization at the Agent, Task, and Crew levels, its internal data flows and collaborative processes often become black boxes, limiting transparency and debugging in complex scenarios. In contrast, LangGraph significantly improves system scalability and maintainability by clearly visualizing the entire workflow with a state-based graph model. In this study, we demonstrate that, in particular, wrapping CrewAI entities as LangGraph nodes enables modular workflows, flexible orchestration, and dynamic tool integration, thereby empirically validating superior performance and scalability in advanced RAG pipelines and domain-specific applications.\\n\\nAssociate Professor,\\n\\nOpen Access http://doi.org/10.6109/jkiice.2019.23.1.399\\n\\npISSN:2234-4772\\n\\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License(http://creativecommons.org/li \\xadcenses/ by-nc/3.0/) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. Copyright The Korea Institute of Information and Communication Engineering.\\n\\n키워드 : 임베딩, 대형 언어 모델, 검색 증강 생성(RAG), 멀티에이전트시스템\\n\\nKeywords : Embedding, LLM(Large Language Model), RAG(Retrieval Augmented Generation), Multi-Agent System\\n\\n## Ⅰ. 서 론\\n\\n대형 언어 모델의 혁신적인 발전은 단순한 질의응 답을 넘어, 보다 복잡하고 맥락적인 문제를 해결할 수 있는 능력을 갖춘 AI 에이전트 시스템의 구현을 가능 케하였다. 그 결과로 단일 LLM 기반 시스템에서 벗어 나, 복수의 에이전트가 각기 다른 역할과 책임을 맡아 상호작용하며 협업하는 MAS(Multi-Agent System) 패 러다임이 자연스럽게 등장했다[1]. 기존의 단일 모델 기반 접근은 모든 정보를 한 모델에 집중시키는 방식 이었으나, 점차 역할 분담과 전문화, 협업 구조가 강조 되면서 다양한 에이전트 프레임워크들이 발전하기 시 작했다. 대표적인 예시로는 AutoGPT, BabyAGI 등 단 일LLM의 자기지향적 플래닝 능력을 시연한 시스템이 있으며, 이후 ChatDev[2], AgentVerse, CAMEL 등에서 는역할기반에이전트구성을바탕으로한협업및대 화 시나리오가 도입되었다. 그러나 이들 대부분은 에 이전트 간의 데이터 흐름이나 시스템 전체의 구조적 투명성, 그리고 유지보수 측면에서한계를 드러냈다.\\n\\n이러한 맥락에서 CrewAI는 역할, 태스크, 크루라는 개념적 단위를 통해, 각 에이전트가 특정 역할을 수행 하고이를구조화하여복잡한협업시나리오를구현할 수있게하였다[3]. CrewAI의 가장 큰 장점은 추상화된 에이전트 설계와 직관적인 역할 분담, 그리고 모듈화 된태스크배정이가능하다는점이다. 특히 복잡한 도 메인에서각에이전트의전문성을명확하게설정할수 있고, 협업의 단위인 크루를 통해 전체 시스템을 계층 적으로 관리할 수 있다. 하지만 내부적으로 데이터 이 동경로나에이전트간상호작용이블랙박스화되기쉽 고, 시스템 전체의 동작 흐름을 시각적으로 추적하거 나, 조건 분기와 반복, 예외 처리 등 복잡한 워크플로 우를관리하기에는다소한계가있었다.\\n\\n이에반해LangGraph는 언어 모델 워크플로우를 그 래프기반상태기계(state machine)로 모델링할 수 있 게함으로써, 각 노드에서의 작업과 상태 전이, 데이터 흐름을 명확히 시각화할 수 있는 장점을 제공한다. LangGraph를 활용하면 복잡한 멀티에이전트 협업 구 조를 그래프 형태로 직관적으로 설계할 수 있으며, 조 건분기, 반복 실행, 오류 처리 등도 노드와 엣지의 조 합만으로 손쉽게 구현할 수 있다. 실제로 LangGraph 는 오케스트레이션 및 상태 지속성, 체크포인트 기능\\n\\n등도지원하여, 장시간 실행되는 멀티에이전트 워크플 로우의 복원성 및 신뢰성을 강화한다[4]. CrewAI와 LangGraph 각각의 강점에도 불구하고, 두 프레임워크 가 분리된 채로는 실제 현장 적용에서 생산성이나 운 영효율성, 확장성 면에서 한계가 명확하다. 따라서 본 연구은 CrewAI의 역할 기반 협업 구조와 LangGraph 의 그래프 기반 오케스트레이션의 장점을 결합하여, 실제로 프로덕션 환경에서 사용할 수 있는 강력하고 유연한통합아키텍처를제시하고자한다.\\n\\n## Ⅱ. 배경 및 기존연구\\n\\n단일 에이전트 시스템의 대표격인 AutoGPT는 ReAct(Reasoning+Acting) 패턴을 활용하여 단일 LLM이 일련의 작업을 순차적으로 수행하는 구조를 제시하였다. 이러한 방식은 복잡한 문제를 하나의 거대한 체인으로 해결한다는 점에서 혁신적이었으나, 협업이 필요한 복합 시나리오에서는 명확한 한계를 드러냈다[5]. 이어 등장한 AutoGen은 전문가 에이전 트 간의 협업과 사용자 프록시 개념을 도입하여 대 화형 코드 생성과 협력적 문제 해결에 대한 가능성 을 확장했다. CrewAI는 에이전트와 태스크, 크루의 명확한 역할 구분을 통해 협업 효율성과 구조적 확 장성을 동시에 달성하였고, 특히 엔티티 기반 장기 메모리와 시나리오 기반 팀워크 설계가 실제 업무에 적합함을 입증했다[3][6].\\n\\nLangGraph는 상태 기반 워크플로우와 메시지 패 싱 시스템을 통합하여, 멀티에이전트 간의 복잡한 협업 로직을 그래프로 시각화하고 통제할 수 있는 아키텍처를 제안하였다. 이를 통해 각 에이전트의 역할과 데이터 이동 경로, 오류 처리 과정, 휴먼 인 더 루프 등 다양한 요구사항을 하나의 구조 안에서 직관적으로 표현할 수 있게 되었다. 최근의 연구들 은 LangGraph가 다양한 언어 에이전트를 조합하여 번역, 질의응답, 멀티도메인 지원 등 복합 문제 해결 에 효과적임을 실험적으로 보여주고 있다[4][7]. 또한, Retrieval-Augmented Generation(RAG) 구조의 발전 에 따라, 단순한 정보 검색을 넘어서 문서 요약, 필 터링, 재질문 등 능동적이고 적응적인 정보 획득 전 략(Agentic RAG, Adaptive RAG)이 멀티에이전트 시 스템에서 실질적 성능 개선을 이끌어내고 있다[8].\\n\\nSTORM과 같은 구조는 에이전트 간 역할 분담이 정 보 수집 및 응답 품질에 중대한 영향을 미친다는 점 을 실험적으로 입증하였다[9].\\n\\n## Ⅲ. 제안 방법 및 아키텍처\\n\\n기존 CrewAI와 LangGraph 프레임워크는 각각 역 할 기반 모듈화와 상태 기반 워크플로우 제어라는 장점을 지니고 있으나, 단독으로는 복잡한 조건 분 기, 평가, 반복, 다양한 도구 통합 등 실제 대규모 멀 티에이전트 시스템 구현에서 한계가 있었다[3][4].\\n\\n본 연구에서 제안하는 통합 구조는 CrewAI의 구 성요소(agent, task, crew)를 LangGraph의 노드로 캡 슐화(wrapping)함으로써, 명확한 상태 기반 흐름 제 어와 모듈화된 워크플로우 오케스트레이션을 동시에 실현한다. 래핑 전략은 시스템의 요구에 따라 Agent 단위, Task/Tool 단위, Crew 단위로 계층화할 수 있 으며, 각 계층별로 제어권한과 유연성을 다르게 부 여할 수 있다[3][4].\\n\\nAgent 단위 래핑은 각 에이전트를 LangGraph 내 독립 노드로 구현하여, 실행 순서, 데이터 흐름, 조건 분기, 반복 등을 세밀하게 제어할 수 있다. 예를 들 어, 특정 에이전트의 출력이 미흡할 경우, 평가 노드 를 통해 조건 분기 후 재실행하거나 다른 에이전트 로 분기하는 복잡한 로직도 명확히 구현할 수 있다. Task/Tool 단위 래핑에서는 검색, 계산, API 호출 등 특정 기능 단위로 노드를 생성하여, 에이전트가 description 기반으로 다양한 도구를 상황에 맞게 해 석·호출할 수 있다[3]. Crew 단위 래핑은 전체 크루 (복수 에이전트와 태스크의 집합)를 단일 LangGraph 노드로 취급함으로써, 이미 정의된 고수준 협업 구 조를 외부에서 블랙박스화하여 재사용성을 높인다. 이러한 다층적 래핑 구조는 실제 개발 시 요구에 따 라 손쉽게 조합할 수 있다.\\n\\n구현 단계에서는, 각 CrewAI 에이전트 및 태스크 를 LangGraph 노드로 정의하고 입력 파라미터, 출력 값, 상태 전이 조건을 명확히 하여 데이터 흐름과 협업 과정을 그래프 형태로 시각화할 수 있다. Tool 사용은 description 필드를 통한 자연어 인터페이스 로 추상화되어, LLM 기반 에이전트가 각 Tool의 목 적과 사용법을 자율적으로 해석, 상황에 맞게 활용\\n\\n하도록 설계하였다. Retriever, 외부 API, 계산기 등 다양한 Tool을 하나의 구조 내에서 통합할 수 있어, 도메인 확장 및 재사용이 매우 용이하다[4].\\n\\n이러한 통합 구조를 통해 다음과 같은 기술적·구 조적 이점을 실현할 수 있었다.\\n\\n첫째, 데이터 흐름과 시스템 실행 경로가 각 노드 단위로 명확히 관리되어, 전체 워크플로우와 응답 처리를 외부에서 체계적으로 제어할 수 있다. 복잡 한 조건 분기, 반복 실행, 실패 대응 등도 그래프 구 조 내에서 일관성 있게 처리할 수 있다.\\n\\n둘째, Tool 호출 및 통합은 description 기반 프롬 프트와 일관된 인터페이스를 활용하여, 다양한 도구 를 자연스럽게 조합할 수 있고, 새로운 도구의 추가· 교체, 도메인 확장도 높은 유연성으로 지원한다.\\n\\n셋째, LangGraph의 상태 기반 제어는 각 노드 실 행 결과에 따른 동적 흐름 전환과 예외 상황 대응, 시스템 신뢰성 향상에 크게 기여한다. 평가 노드를 독립적으로 추가하여, BLEU, ROUGE, factual consistency 등 자동화된 품질 메트릭과 human in the loop 평가도 효과적으로 연계할 수 있다[10]. 이 러한 평가지표와 평가 방식은, 본 논문의 실험뿐만 아니라 최근 RAG 및 NLP 분야에서 성능 비교와 품 질 검증의 객관적·표준적 기준으로 널리 채택되고 있다.\\n\\n## Ⅵ. 실험 및 평가\\n\\n본 연구에서는 AI 기술 관련 문서, 법률·의료 도메 인 문서, 연구 지원형 멀티에이전트 시스템 등 세 가지 유형의 실험군을 설정하여, 각 시스템의 성능 을 정량적·정성적으로 평가하였다. 첫 번째 실험군은 일반 AI 문서를 대상으로 한 RAG 시스템으로, RAGAS Question Generator 및 Critic을 활용한 Faithfulness, Answer relevancy, Context Recall, Context Precision, LLM Score 등의 지표로 평가하였 다. CrewAI+LangGraph(멀티툴 통합형)는 모든 평가 항목에서 기존 RAG 대비 높은 점수를 기록하였다. 특히 멀티툴 통합형은 LLM Score 4.24, Faithfulness 0.87 등 가장 우수한 성과를 보였다.\\n\\nFig 1. AI Document RAG Metrics (General Domain). The chart compares four configurations across five evaluation metrics: Faithfulness, Answer Relevancy, Context Recall, Context Precision, and LLM Score.\\n\\n위 그림1은, Crew AI(Only Retriever)는 Faithfulness(0.87)에서 가장 높은 점수를 기록하며, 원문 근거에 충실한 응답 생성에서 강점을 보였다. Answer Relevancy는 Multi Tool 구성에서 최고점 (0.97)을 기록, 복수 도구 통합이 질문 의도 적합도 에 크게 기여함을 알 수 있다. Context Recall은 전 반적으로 고르게 분포되어 있으나 Only Retriever가 소폭 우위를 보인다. 반면 Context Precision은 Naive 및 Advanced RAG에서 더 높게 나타나, 단순 한 검색 구조가 맥락의 정밀도에는 유리할 수 있음 을 시사한다. LLM Score 역시 Multi Tool에서 가장 높게 나타나, LLM 기반 생성 품질(창의성, 응답 일관 성 등) 향상에 멀티툴 전략이 효과적임을 확인하였 다.\\n\\n두 번째 실험은 법률 도메인에 특화된 QA 시스템 을 대상으로, 정확성, 완결성, 명료성 등 실질적 응답 품질 기준을 적용하여 평가하였다. 법률 분야 특성 상, 답변의 정답 일치도, 필수 정보 누락 여부, 용어· 조문 인용의 명확성 등이 실용적 평가 기준이 되었 다. CrewAI+LangGraph(멀티툴)는 모든 항목에서 평 균 8.94점으로 가장 높은 성능을 나타냈으며, 단일 Tool이나 기존 RAG 대비 복잡한 질의에도 높은 적 합성과 완성도를 보였다.\\n\\nFig 2. Legal Domain RAG Metrics. A comparative visualization of three RAG configurations-Advanced RAG, Craw AI (Only Retriever), and Craw AI (Multi Tool)-across four evaluation metrics: Accuracy, Completeness, Clarity, and Final Score.\\n\\n그림 2는 법률 도메인에서 세 가지 RAG 구성 (Advanced RAG, Craw AI 단일 Retriever, Craw AI Multi Tool)의 네 가지 평가 지표(정확성, 완전성, 명 료성, 종합점수)별 성능을 시각적으로 비교한 것이다. Advanced RAG는 대부분의 항목에서 고르게 높은 점수(9점대)를 기록했으나, Metric 4에서는 7.4점으로 다소 부족함을 보였다. Craw AI (Only Retriever)는 전반적으로 낮은 점수(78점대)를 기록하여, 단일 검 색만으로는 법률 문서의 정확성과 완전한 커버리지 에 한계가 있음을 시사한다. 반면 Craw AI (Multi Tool)는 모든 지표에서 가장 높은 점수(69.13)를 보 여, 툴 결합이 Retrieval-Generation 품질을 현저히 향상시킴을 실증적으로 보여준다.\\n\\nSTORM RAG와 CrewAI + LangGraph 시스템의 성능을 총 15개의 세부 기준으로 평가하였다. 각 기 준은 주제 적합성, 구조 비교의 명확성, 개념적 정확 성, 고급 검색 전략 활용, 생성 전략 다양성, 평가 메 트릭 활용, 복잡 질의 대응력, 시스템 아키텍처 설명 력, 실제 적용사례, 논리 구조 및 문장 가독성, 참고 문헌 신뢰성 등 다양한 측면을 포괄한다. 두 시스템 모두 주제 적합성, 개념적 정확성에서 만점을 기록 하는 등 기본적인 측면에서 강점을 보였다. 그러나 CrewAI + LangGraph는 모듈형 아키텍처의 명확성, 실제 배포와 운영 유연성, 통합 가능성, 도메인별 실 제 적용사례, 설명의 명확성 및 출처 신뢰도 측면에 서 STORM RAG 대비 더 높은 평가를 받았다.\\n\\n총점 기준으로는 STORM RAG가 68.5점, CrewAI + LangGraph가 71.0점으로 집계되었다. CrewAI + LangGraph가 STORM RAG 대비 약 2.5점 높은 점수 를 기록하며 전반적인 우위를 보였다. 이 결과는 명 확성, 통합 유연성, 엔드투엔드 추론 능력 등에서 모 듈형 RAG 구조의 설계적·운영적 강점을 뚜렷하게 보 여준다. 특히 실제 현장에 요구되는 높은 적응성, 확 장성이 필요한 상황에서 CrewAI + LangGraph의 효 과적 우위가 실증적으로 확인되었다.\\n\\n자동 평가(RAGAS) 도구의 경우, 도메인 특화 문서 에서는 핵심 개념 누락, 문맥 오도, 케이스 커버리지\\n\\n불완전, 중복 질문 등 한계가 드러났으며, 실제 현장 에서는 전문가 수작업 검수 및 별도의 평가 기준(15 항목, 5점 척도) 도입이 필수적임을 확인하였다. 다 음은 각 metric에 대한 정확한 점수이다.\\n\\nTable. 1 Comparison of RAG Configurations in the Legal Domain Across Four Evaluation Metrics\\n\\n| System                   |   Metric1 |   Metric2 |   Metric3 |   Metric4 |\\n|--------------------------|-----------|-----------|-----------|-----------|\\n| Advanced RAG             |      9    |       9   |      9    |      7.4  |\\n| CrewAI (Only Retriever)  |      8.17 |       7.6 |      8.13 |      7.97 |\\n| CrewAI ( M u l t i Tool) |      9.13 |       8.6 |      9.1  |      8.94 |\\n\\n그림 2의 Metric 1~4는 각각 정확성(Accuracy), 완전 성(Completeness), 명료성(Clarity), 종합점수(Final Score)에 해당한다.\\n\\nCrewAI와 LangGraph의 통합 구조는 기존 코드 수정 없이 노드 단위 wrapping만으로 다양한 워크 플로우 및 조건 분기를 유연하게 설계할 수 있어, 통합 비용 절감, 코드 재사용성, 유지보수 효율성 측 면에서 현저한 개선 효과를 확인하였다. 이러한 장 점들은 실제 실험과 도메인별 적용을 통해 확인되었 으며, 기존 연구에서 한계로 지적되었던 복잡한 분 기, 반복, 평가, 동적 도구 통합, 유지보수 측면의 문 제를 효과적으로 해결하였다.\\n\\n## Ⅴ. 심층 분석 및 비교\\n\\nLangGraph 단독 사용 시, 그래프 기반의 고도로 사용자 정의 가능하고 제어 가능한 에이전트 워크플 로우를 구축할 수 있다. 이는 복잡한 조건 분기, 상 태 관리, 다양한 외부 시스템과의 연동 등에서 강력 한 제어력과 확장성을 제공한다는 점에서 명확한 강 점이 있다. 그러나 CrewAI에 비해 에이전트 역할 정 의와 협업 관리가 상대적으로 복잡하며, 모든 협업 논리를 사용자가 직접 설계하고 구현해야 한다는 점 에서 개발자의 부담이 커질 수 있다. 학습 곡선 역 시 상대적으로 높아, 대규모 시스템의 초기 설계 및 반복적인 디버깅에 더 많은 시간이 요구된다.\\n\\n반면 CrewAI는 사용 편의성과 협업적 지능에 중 점을 둔 구조로, 에이전트 간 역할 기반 협업이 프 레임워크 차원에서 내장되어 있다. 이를 통해 복잡 한 멀티에이전트 시스템도 빠르게 설계하고 운영할 수 있으며, 실제 프로토타입 제작이나 반복적인 시 스템 확장에 특히 유리하다. 하지만 워크플로우의 세밀한 제어, 조건 분기, 상태 지속성, 외부 시스템과 의 폭넓은 통합과 같은 부분에서는 한계를 드러낸다. CrewAI만으로는 복잡한 애플리케이션에서의 정교한 오케스트레이션이 어렵고, 개발자가 직접 세부 제어 를 구현하기에는 구조적인 제약이 있다.\\n\\n이에 반해 두 프레임워크를 결합한 통합 아키텍처 는 각각의 강점을 상호 보완할 수 있다. 통합형 구 조에서는 LangGraph가 제공하는 그래프 기반의 워 크플로우 관리와 CrewAI의 역할 기반 에이전트 설 계를 함께 활용함으로써, 복잡한 멀티에이전트 시스 템에서도 제어와 사용 편의성 간의 균형을 달성할 수 있다. 구체적으로, CrewAI의 높은 수준의 협업 설 계와 LangGraph의 세밀한 워크플로우 제어를 동시 에 활용하여, 복잡성 관리와 아키텍처 설계의 명확 성을 확보할 수 있다. 물론 통합형 구조는 두 프레 임워크 모두에 대한 충분한 이해가 요구되며, 학습 곡선이 단일 프레임워크에 비해 다소 높을 수 있다. 그러나 명확한 아키텍처 및 인터페이스 설계를 통해 실제 현장 적용 시 개발 생산성, 운영 효율성, 품질· 확장성 등 여러 측면에서 실질적인 이점을 얻을 수 있었다. 특히 본 연구의 통합 구조는 실제 배포 경 험과 다양한 도메인 실험을 통해 높은 적응성과 실 효성을 보였다. 복잡한 조건 분기, 외부 시스템 연동, 도메인별 맞춤형 협업 등 실무적 요구를 통합 구조 가 효과적으로 충족시켰다. 이러한 분석은 향후 대 규모 AI 오케스트레이션 환경에서 통합형 아키텍처 가 더욱 중요한 역할을 하게 됨을 시사한다.\\n\\n## Ⅵ. 결론\\n\\n본 연구은 CrewAI의 직관적인 에이전트 설계와 LangGraph의 상태 기반 오케스트레이션 구조를 통 합한 새로운 아키텍처를 제시하였다. Crew, Agent, Task/Tool 단위로 세분화된 래핑 전략과 명확한 상 태 기반 워크플로우 설계를 통해, 실제로 다양한 도\\n\\n메인에서 높은 성능과 유연성을 보장하는 멀티에이 전트 시스템을 구현할 수 있음을 실험적으로 입증하\\n\\n였다. 데이터 흐름의 시각화, 조건 분기 및 반복, Tool 통합, 평가 노드 삽입, Human-in-the-loop 감 독 구조 등 통합 아키텍처만의 강점은 프로덕션 환 경에서의 실질적 효율성과 성능 향상으로 이어졌다. 그러나 LangGraph와 CrewAI 통합에는 상태 관리 불일치, 데이터 공유 방식 차이, 통신 패턴 조정 등 에서 구현상의 복잡성이 뒤따르며, 두 프레임워크 모두에 대한 깊은 이해가 필요하다. 이러한 점은 단 일 프레임워크 대비 높은 학습 곡선과 설계 비용을 유발할 수 있다. 향후 연구에서는 상태 동기화 인터 페이스, 도메인 특화 멀티에이전트 템플릿 개발, 실 시간 피드백 기반 튜닝, 평가 워크플로우 자동화 도 구 개발 등이 주요 과제로 남아 있다. CrewAI+LangGraph 기반 통합 구조는 단순 도구 결 합을 넘어, 모듈성, 제어력, 협업성을 동시에 확보할 수 있는 새로운 기준점이 될 것이며, LLM 기반 AI 오케스트레이션 분야의 실질적 전환점을 제공할 것 으로 기대한다. 본 연구의 통합 아키텍처는 다양한 도메인에서의 실험을 통해 뛰어난 성능과 유연성을 입증했으며, 향후에는 상태 동기화 자동화, 도메인별 특화 템플릿, 실시간 평가 및 피드백 기반 튜닝 등 실무적 연구가 활발히 이루어질 필요가 있다.\\n\\n결론적으로, CrewAI+LangGraph 구조는 실제 서비 스 및 다양한 도메인에서의 적용을 통해 우수한 성 능과 효과를 실증적으로 확인하였으며, 향후 LLM 기 반 멀티에이전트 시스템의 발전에 크게 기여할 것으 로 기대된다.\\n\\n## REFERENCES\\n\\n- [1] M. Hossain and A. S. Mian, 'A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions,' arXiv preprint arXiv:2402.01968, Feb. 2024. DOI: 10.48550/arXiv.2402.01968.\\n- [2] ChatDev: Communicative Agents for Software Development, arXiv preprint arXiv:2307.07924, Jul. 2023. DOI: 10.48550/arXiv.2307.07924.\\n- [3] crewAIInc, 'CrewAI: A Framework for Role-Based Multi-Agent Collaboration,' GitHub repository, 2023. Available: https://github.com/crewAIInc/crewAI\\n- [4] LangChain, 'LangGraph: Build resilient language agents as graphs,' GitHub repository, 2024. Available: https://github.com/langchain-ai/langgraph\\n- [5] Significant Gravitas, 'Auto-GPT: An Autonomous GPT-4 Experiment,' GitHub repository, 2023. Available: https://github.com/Torantulino/Auto-GPT\\n- [6] P. Venkadesh, S. V. Divya, and K. Subash Kumar, ' Unlocking AI Creativity: A Multi-Agent Approach with CrewAI,' arXiv preprint arXiv:2412.09345, Dec. 2024. DOI: 10.48550/arXiv.2412.09345.\\n- [7] J. Wang and Z. Duan, 'Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models,' arXiv preprint arXiv:2412.03801, Dec. 2024. DOI: 10.48550/arXiv.2412.03801.\\n- [8] A. Singh, M. Kumar, Y. M. Purohit, and M. Shrivastava, 'Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG,' arXiv preprint arXiv:2501.09136, Jan. 2025. DOI: 10.48550/arXiv.2501.09136.\\n- [9] Y. Shao, Y. Jiang, T. A. Kanell, P. Xu, O. Khattab, and M. S. Lam, 'Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models,' arXiv preprint arXiv:2402.14207, Feb. 2024. DOI: 10.48550/arXiv.2402.14207.\\n- [10] H. Li, M. Zhang, Z. Liu, et al., 'LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods,' arXiv preprint arXiv:2412.05579, Dec. 2024. DOI: 10.48550/arXiv.2412.05579.\\n\\n## 김재호(Jae-Ho Kim)\\n\\n수원대학교컴퓨터학부학사 수원대학교컴퓨터학부석사 수원대학교컴퓨터학부박사과정 Langchain Opentutorial Core Contributor\\n\\n※관심분야: 인공지능, LLM, RAG, AI Agent\\n\\n## 김장영(Jang-Young Kim)\\n\\n연세대학교컴퓨터과학공학사 Pennsylvania State Univ. 공학석사 State University of New York 공학박사 University of South Carolina 교수 수원대학교컴퓨터학부교수\\n\\n※관심분야: Big data, AI, Cloud computing, Networks\\n\\n\")]\n"
     ]
    }
   ],
   "source": [
    "print(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9507acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc77a0",
   "metadata": {},
   "source": [
    "## 데이터 분할(Chunking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66a87b",
   "metadata": {},
   "source": [
    "### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5eadb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_experimental.text_splitter import SemanticChunker\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# bge_m3_embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "# semantic_chunker = SemanticChunker(bge_m3_embeddings)\n",
    "\n",
    "# semantic_chunker_docs = semantic_chunker.split_documents(all_docs)\n",
    "# len(semantic_chunker_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c989c",
   "metadata": {},
   "source": [
    "### Recursive Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 일반 텍스트용 splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100\n",
    ")\n",
    "split_documents = text_splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd25cb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ece30",
   "metadata": {},
   "source": [
    "# SAVE: Qdant Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956269c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore, FastEmbedSparse, RetrievalMode\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import Distance, VectorParams, SparseVectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38154f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = QdrantClient(\":memory:\") → 인메모리 벡터 저장소 생성.\n",
    "client = QdrantClient(host=\"localhost\", port=6333) # docker를 이용해 사용. 따라서 포트번호가 필요함.\n",
    "\n",
    "collection_name = \"RAG_Template\"\n",
    "\n",
    "dense_embedding = OllamaEmbeddings(model=\"bge-m3\")\n",
    "sparse_embedding = FastEmbedSparse(model_name=\"Qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f60239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collection 생성\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config={\"dense\": VectorParams(size=1024, distance=Distance.COSINE)},\n",
    "    sparse_vectors_config={\"sparse\": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d53c2d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f68e452f0152426c8014cecaf5ef32dd',\n",
       " 'fa8a2cfee5954cdba29eff36201045d4',\n",
       " '3d900874c65a46e48a1f476191d646cb',\n",
       " '27c523eeb47d44609154fe25d01ea2f4',\n",
       " 'f2ef71f6e19f4dfeb9b123b9882cbf29',\n",
       " 'ddb2880859d646168e6b374a2a949ad2',\n",
       " '01a8961c635a4adebb5fe443811f0df6',\n",
       " 'e8eb10ebae8c45f18a2123600e8f1424',\n",
       " 'ab4deb4a72bd416fab60f1707273d33a',\n",
       " 'eff19cee6b6b4df197ca799914fa2c5d',\n",
       " '24fd77272d33440086c605d7e84a5aaa',\n",
       " '22e7caefd82340f58c01a7159915e247',\n",
       " 'abb52489ec2f46e5b7c992a5115dbbb8',\n",
       " '144dc4407b574005b562fe1349c030af',\n",
       " 'b9b77e8ce2d4473bac51fc592dfc09b0',\n",
       " '665201220de34df1b10a9e7c4ee2ff8b',\n",
       " 'cc239b7d9ed14cb69f808c3b8bd18cb4',\n",
       " 'ef713baac9194439abf652e18204f1cb',\n",
       " '0b97e1fa643e4713aa1b3decc7c525f8',\n",
       " '03c8d941491544c2bfb8b0336e00cf5f',\n",
       " 'a20397af7f3448bab356e29134f0c0b7',\n",
       " 'ddc9498ac9744efd946d836c5daf7de4',\n",
       " '743144d9dd574734b3426b85896006f9',\n",
       " '324182df84cc47cea826b17696aea0a4',\n",
       " '6711799458a240b78638e1047126a764',\n",
       " 'b4fe0d1486d244d8a3b5408761602c19',\n",
       " 'e1ac8710b490438eb5db8cc82525fddd',\n",
       " '3f0fb5c9c8c44fb987a11f5a39133e59',\n",
       " 'b506eff62bc044ddb36999d0a234b67e',\n",
       " '58e37be7c1374717af1d2ee4805d1a6a',\n",
       " '8c571ba39c024ee3b67881a23c08a26c',\n",
       " '3f08cd5f19424ae0a358bc17253d9b97',\n",
       " '598ff84f6e5c4c6383f89c64611efe4d',\n",
       " '79977a6c49954a0fb7b8c293ec3c2b9c',\n",
       " '4ae219f29ebf4e529e78052532327da1',\n",
       " 'fc3ee1d09916434ca6720707104fb165',\n",
       " 'bf4acf7bd9fa41a5aa5a6addf8841012',\n",
       " 'f929548353734823b7bf12b924575d1e',\n",
       " 'f8db0f35fe5d41aab8a18dd46c5cb85b',\n",
       " '5f52767b2a354169abea7b21fb1beded',\n",
       " '130c6a929c3c4a0dab1e086bd3769505',\n",
       " 'adb7280022a94e09be1d9cfdf828da12',\n",
       " '4872536d82f74ab6b82d425e0848d90c',\n",
       " 'babfbeef58c04ac5ad8d15fce9d78b68',\n",
       " 'a247ad54eda6491b8f8728d4341eb59e',\n",
       " 'f79bf52576894897a68d676b7e5a54c9',\n",
       " '746eebd3eb9340c5ac29db5c1561ca16',\n",
       " 'f864583b4a7b43f8a48dc44ff3169eb6',\n",
       " '0db31c64a25647daa5f2f5d6f150daea',\n",
       " '347ceb7653724f7bad4f9b364069dffb',\n",
       " 'd8d6de39476e4879a2c060a94bc9d581',\n",
       " 'dc040cfb21b34997bc4477c92e442282',\n",
       " '0f25f0bb876c49f59156fb3a42813005',\n",
       " 'd9c92aa853fb47dba250f7363b774d40',\n",
       " '00695e26f46e4dc59d9062187c3f29d9',\n",
       " '0046798e59f4431d873e34511d3a2cf5',\n",
       " '1dad3813975344f2a7602945c33c4f3b',\n",
       " 'ee2d2d5b857d4cd5a649445a3dc622fa',\n",
       " '900748ee907d411aa8731ace965662e2',\n",
       " 'ab11929cceb94439aa9ae7c256aabb18',\n",
       " '5383d0239ec6471084a5e9961a425b1a',\n",
       " '2b3742047bf74cd984cbdba441e92715',\n",
       " '274ebcff896f44779233ec9e3e787631',\n",
       " 'ae835789ba6047d0909a363e08aa7c3d',\n",
       " 'e1fabb1d90344ade84bac655336a5b1d',\n",
       " 'ad383a7b757748ad97234ddeea09d84a',\n",
       " '54c4f4a497174242a6545fa1dfce0968',\n",
       " 'f3d96a0c66284668bfdbcec378359994',\n",
       " '8b3a9c1d113f4bd98060409a9e421cf7',\n",
       " 'e7c46f4b9c9f471d90b32ea79d96724a',\n",
       " '876871e432864dc5856ef15de2104126',\n",
       " '47b622f77f064045bbd9d66ee509ef89',\n",
       " '1b01fc002a204ec2b4e47109c686816f',\n",
       " '9d1b0d3ab3a64a8fa72de1105a414036',\n",
       " 'cdf0b546feca4fa58363f1a148a8ccf6',\n",
       " '07466e883d27414db935bb99842d4def',\n",
       " '14f18005d5af434cae8b6d7a36eedc2c',\n",
       " '0b6e0843dd2f4b7bad353b6964fc1f4a',\n",
       " 'd9dbb025c2b64813a5d9dac95d1d0f0d',\n",
       " 'b901b2daebeb4086b6ee32f61f7a5e56',\n",
       " '1117eb819a6c45278b241b4b9fd81185',\n",
       " '47d6f8b6ba87432a94701393f15af4d0',\n",
       " '7109b8bc69d840cda9269c314f266226',\n",
       " '3aa968299c8c49ad97700ea7f8fdbb1a',\n",
       " 'e6e7834aeb274f08bfcdeea73b93f0b3',\n",
       " '95b08f51ea5441f9aa1518cc0a1ab5ed']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=dense_embedding,\n",
    "    sparse_embedding=sparse_embedding,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    vector_name=\"dense\",\n",
    "    sparse_vector_name=\"sparse\"\n",
    ")\n",
    "\n",
    "qdrant.add_documents(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0faf7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qdrant.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8d341b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 2는 법률 도메인에서 세 가지 RAG 구성 (Advanced RAG, Craw AI 단일 Retriever, Craw AI Multi Tool)의 네 가지 평가 지표(정확성, 완전성, 명 료성, 종합점수)별 성능을 시각적으로 비교한 것이다. Advanced RAG는 대부분의 항목에서 고르게 높은 점수(9점대)를 기록했으나, Metric 4에서는 7.4점으로 다소 부족함을 보였다. Craw AI (Only Retriever)는 전반적으로 낮은 점수(78점대)를 기록하여, 단일 검 색만으로는 법률 문서의 정확성과 완전한 커버리지 에 한계가 있음을 시사한다. 반면 Craw AI (Multi Tool)는 모든 지표에서 가장 높은 점수(69.13)를 보 여, 툴 결합이 Retrieval-Generation 품질을 현저히 향상시킴을 실증적으로 보여준다.\n"
     ]
    }
   ],
   "source": [
    "query = \"self-rag\"\n",
    "print(response.invoke(query)[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9532b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docling_outputs\\\\LangGraph-Based Integrated Architecture for CrewAI Multi-Agent.pdf.md', '_id': '8b3a9c1d-113f-4bd9-8060-409a9e421cf7', '_collection_name': 'RAG_Template'}, page_content='그림 2는 법률 도메인에서 세 가지 RAG 구성 (Advanced RAG, Craw AI 단일 Retriever, Craw AI Multi Tool)의 네 가지 평가 지표(정확성, 완전성, 명 료성, 종합점수)별 성능을 시각적으로 비교한 것이다. Advanced RAG는 대부분의 항목에서 고르게 높은 점수(9점대)를 기록했으나, Metric 4에서는 7.4점으로 다소 부족함을 보였다. Craw AI (Only Retriever)는 전반적으로 낮은 점수(78점대)를 기록하여, 단일 검 색만으로는 법률 문서의 정확성과 완전한 커버리지 에 한계가 있음을 시사한다. 반면 Craw AI (Multi Tool)는 모든 지표에서 가장 높은 점수(69.13)를 보 여, 툴 결합이 Retrieval-Generation 품질을 현저히 향상시킴을 실증적으로 보여준다.'),\n",
       " Document(metadata={'source': 'docling_outputs\\\\insight_Agentic.pdf.md', '_id': '4ae219f2-9ebf-4e52-9e78-052532327da1', '_collection_name': 'RAG_Template'}, page_content='## Ⅴ. 결론 및 향후연구\\n\\n본 논문에서는 Fine-tuning 기반 SLM과 RAG 의 구조적 차이와 장단점을 비교 분석하고, RAG 와 Agentic RAG 시스템 설계 시 고려해야 할 주요 이슈들을 실험적으로 제시하였다. \"다양한 실험과 분석을 통해 텍스트 분할 방식, 임베딩'),\n",
       " Document(metadata={'source': 'docling_outputs\\\\insight_Agentic.pdf.md', '_id': 'eff19cee-6b6b-4df1-97ca-799914fa2c5d', '_collection_name': 'RAG_Template'}, page_content='본 논문에서는 RAG 시스템을 구현하면서 경험한 다양한 사례를 바탕으로, RAG 구조와 Agentic 환경 에서의 LLM 및 Embedding 모델 선택이 시스템 성능 에 미치는 영향, 텍스트 분할 및 노드 구조에 따른 출 력 방식과 무한루프 발생 가능성등을 고찰한다.이를 통해 기존 연구에서 다루지 않은 실제적인 RAG 설계 및운용인사이트를제시하고자한다.\\n\\n## 1.1 Fine-Tuning과 RAG\\n\\nFine-tuning은 특정 작업이나 도메인에 맞춰 LLM 의 파라미터를 재학습시켜, 해당 지식을 모델 내부에 내재화하는 방식이다. 이는 특정 도메인 지식에 특화 된 경량 모델 구현, 프롬프트 단순화 등의 이점을 제 공하나, 대규모 연산 자원, 고품질 데이터, 장시간의 학습이 필요하며 오버피팅, 데이터 편향, 파라미터 충 돌등의문제가발생할수있다[2].'),\n",
       " Document(metadata={'source': 'docling_outputs\\\\insight_Agentic.pdf.md', '_id': '24fd7727-2d33-4400-86c6-05d7e84a5aaa', '_collection_name': 'RAG_Template'}, page_content='반면, RAG는 외부 문서 기반 검색을 통해 LLM이 내재하지 않은 지식을 실시간으로 보완하는 구조이다. RAG는 실시간성, 도메인 유연성, 최신 정보 반영 등 에서 강점을 가지며, 데이터 품질 부담이 상대적으로 낮고, 할루시네이션 현상 완화 및 재학습 불필요성 등 의장점이있다. 단, 검색 및 임베딩 성능에 따라 답변\\n\\n의 품질이 좌우되며, 복잡한 질문이나 맥락에서는 성 능저하가발생할수있다[3].\\n\\nAI 에이전트 기반 modular RAG가 등장하여, 다양 한 도구 및 메모리, 사전 지식을 바탕으로 복합적인 검색 및 추론을 수행하는 구조가 제안되고 있다. 이러 한 구조에서는 각 에이전트가 도메인별 데이터 검색 및 답변 생성을 담당하며, fine-tuning이 제공하는 지 식내재화효과를일정부분대체할수있음을시사한 다[4].\\n\\nFig. 1 Workflow Comparison of Fine-Tuning and RAG')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
